# TODO: Refatora√ß√£o para Arquitetura de Agente √önico + Utilit√°rios

**Data:** 05 de fevereiro de 2026  
**Objetivo:** Substituir pipeline de 4 agentes LLM por arquitetura Otto (agente √∫nico) + agentes utilit√°rios paralelos  
**Status (05/fev/2026):** Conclu√≠do. Pipeline legado removido; documento mantido como refer√™ncia hist√≥rica.
**Refer√™ncia:** REGRAS_E_PADROES.md (raiz do reposit√≥rio)  
**Estimativa:** 1-2 dias de desenvolvimento

---

## Contexto da Refatora√ß√£o

### Arquitetura Atual (a remover)
```

Pipeline sequencial de 4 agentes LLM:
StateAgent ‚Üí ResponseAgent ‚Üí MessageTypeAgent ‚Üí DecisionAgent
‚îú‚îÄ Custo: ~\$0.0009/msg (4 chamadas LLM)
‚îú‚îÄ Lat√™ncia: ~3-4s
‚îî‚îÄ Problema: Over-engineering para est√°gio atual

```

### Arquitetura Alvo
```

ExtractionAgent (paralelo) ‚Üí Preenche LeadContact
TranscriptionAgent (se √°udio) ‚Üí Converte para texto
‚Üì
OttoAgent (√∫nico)
‚îú‚îÄ Context injection din√¢mico por vertente
‚îú‚îÄ Structured outputs (Pydantic)
‚îî‚îÄ Decide estado + gera resposta + escolhe tipo msg
‚Üì
ValidationPipeline (h√≠brido)
‚îú‚îÄ Gate 1: Determin√≠stico (sempre)
‚îú‚îÄ Gate 2: Confidence check
‚îî‚îÄ Gate 3: LLM review (se 0.7 < conf < 0.85)

```

**Ganhos esperados:**
- Custo: -66% (~$0.0003/msg)
- Lat√™ncia: -25% (~2-2.5s)
- Qualidade: +40% (extra√ß√£o estruturada)
- Manutenibilidade: +100% (c√≥digo mais simples)

---

## FASE 1: REMO√á√ÉO

### 1.1 Remover Pipeline de 4 Agentes ‚ùå

**Arquivos a deletar:**
```bash
src/ai/models/state_agent.py
src/ai/models/message_type_selection.py
src/ai/prompts/state_agent_prompt.py
src/ai/prompts/message_type_agent_prompt.py
src/ai/prompts/decision_agent_prompt.py
src/ai/services/_orchestrator_helpers.py  # Helpers do pipeline antigo
src/ai/utils/agent_parser.py  # Parsers dos 4 agentes
```

**Arquivos a refatorar (n√£o deletar):**

```bash
src/ai/models/response_generation.py  # Aproveitar estruturas
src/ai/models/decision_agent.py       # Aproveitar l√≥gica de decis√£o
src/ai/services/orchestrator.py       # Reescrever como OttoAgent
```

**Checklist:**

- [ ] Backup dos arquivos atuais (criar branch `backup/4-agents-pipeline`)
- [ ] Deletar arquivos listados
- [ ] Remover imports dos arquivos deletados em:
- [ ] `src/ai/__init__.py`
- [ ] `src/app/use_cases/whatsapp/process_inbound_canonical.py`
- [ ] Executar `ruff check src/` (sem erros de import)
- [ ] Commit: `refactor: remove 4-agent pipeline`

---

### 1.2 Remover Testes dos Agentes Antigos ‚ùå

**Arquivos a deletar:**

```bash
tests/test_ai/test_models_state_agent.py
tests/test_ai/test_models_decision_agent.py
tests/test_ai/test_utils_agent_parser.py
tests/test_ai/test_agent_prompts.py
tests/test_ai/test_ai_pipeline.py  # Pipeline antigo
```

**Checklist:**

- [ ] Deletar testes listados
- [ ] Executar `pytest tests/` (ignorar falhas esperadas)
- [ ] Commit: `test: remove 4-agent pipeline tests`

---

## FASE 2: AGENTES UTILIT√ÅRIOS (Dias 3-4)

### 2.1 ExtractionAgent ‚úÖ **PRIORIT√ÅRIO**

**Objetivo:** Extrair informa√ß√µes estruturadas para preencher `LeadContact`

**Arquivo:** `src/ai/services/extraction_agent.py`

**Implementa√ß√£o:**

```python
"""
Agente especializado em extrair informa√ß√µes estruturadas.

Responsabilidades:
- Extrair dados pessoais (nome, email, telefone, empresa)
- Identificar servi√ßos de interesse (SaaS, Sob Medida, etc)
- Detectar urg√™ncia e necessidade espec√≠fica
- Estimar score de confian√ßa da extra√ß√£o

Conformidade REGRAS_E_PADROES.md:
- ¬ß 1.2 SRP: √önica responsabilidade (extraction)
- ¬ß 4: Arquivo ‚â§ 200 linhas
- ¬ß 5: PT-BR, snake_case, type hints
- ¬ß 6: Logs estruturados sem PII
"""

from pydantic import BaseModel, Field
from openai import AsyncOpenAI
from typing import Literal
import re
from config.logging import get_logger

logger = get_logger(__name__)

class ExtractedLeadInfo(BaseModel):
    """Schema de output do ExtractionAgent (structured output)."""
    
    name: str | None = Field(None, description="Nome completo se mencionado")
    email: str | None = Field(None, description="Email v√°lido")
    phone: str | None = Field(None, description="Telefone BR (com DDD)")
    company: str | None = Field(None, description="Nome da empresa")
    role: str | None = Field(None, description="Cargo/fun√ß√£o")
    
    service_interest: list[Literal[
        "saas", "sob_medida", "gestao_perfis", 
        "trafego_pago", "automacao_atendimento", "intermediacao"
    ]] = Field(default_factory=list, description="Servi√ßos mencionados")
    
    urgency: Literal["low", "medium", "high", "urgent"] | None = None
    budget_indication: str | None = Field(None, max_length=100)
    specific_need: str | None = Field(None, max_length=150)
    
    extraction_confidence: float = Field(ge=0.0, le=1.0)

class ExtractionAgent:
    """Agente utilit√°rio para extra√ß√£o de informa√ß√µes."""
    
    def __init__(self, openai_client: AsyncOpenAI):
        self.client = openai_client
        self.model = "gpt-4o-mini"  # Barato e r√°pido
    
    async def extract(
        self,
        user_message: str,
        conversation_context: list[str] | None = None
    ) -> ExtractedLeadInfo:
        """
        Extrai informa√ß√µes estruturadas da mensagem.
        
        Executa EM PARALELO com OttoAgent (n√£o aumenta lat√™ncia).
        """
        # Implementar conforme spec
        pass
```

**Checklist:**

- [ ] Criar `src/ai/services/extraction_agent.py`
- [ ] Implementar `ExtractedLeadInfo` (Pydantic BaseModel)
- [ ] Implementar `ExtractionAgent.extract()` com structured outputs
- [ ] Adicionar valida√ß√µes:
- [ ] Email: regex RFC 5322
- [ ] Telefone: formato brasileiro (11) 9XXXX-XXXX
- [ ] Service interest: apenas valores v√°lidos
- [ ] Adicionar logging estruturado (sem PII):

```python
logger.info("extraction_completed", extra={
    "fields_extracted": len([v for v in result.model_dump().values() if v]),
    "confidence": result.extraction_confidence,
    "tokens": response.usage.total_tokens,
    "cost_usd": response.usage.total_tokens * 0.00000015
})
```

- [ ] Testar isoladamente (criar `tests/test_ai/test_extraction_agent.py`)
- [ ] Garantir arquivo ‚â§ 200 linhas (¬ß 4)
- [ ] Executar `ruff check src/ai/services/extraction_agent.py`
- [ ] Commit: `feat(ai): add ExtractionAgent with structured outputs`

---

### 2.2 TranscriptionAgent ‚úÖ **CR√çTICO PARA WHATSAPP**

**Objetivo:** Transcrever √°udios do WhatsApp para texto

**Arquivo:** `src/ai/services/transcription_agent.py`

**Implementa√ß√£o:**

```python
"""
Agente especializado em transcri√ß√£o de √°udios.

Responsabilidades:
- Transcrever √°udio WhatsApp (formato OGG/Opus)
- Usar Whisper API (OpenAI)
- Detectar idioma automaticamente
- Estimar confian√ßa da transcri√ß√£o

Conformidade REGRAS_E_PADROES.md:
- ¬ß 4: Arquivo ‚â§ 200 linhas
- ¬ß 6: Logs sem conte√∫do do √°udio (apenas metadata)
"""

from dataclasses import dataclass
from openai import AsyncOpenAI
import httpx
from config.logging import get_logger

logger = get_logger(__name__)

@dataclass
class TranscriptionResult:
    """Resultado da transcri√ß√£o."""
    text: str
    language: str
    duration_seconds: float
    confidence: float  # Estimado
    error: str | None = None

class TranscriptionAgent:
    """Agente utilit√°rio para transcri√ß√£o de √°udios."""
    
    def __init__(self, openai_client: AsyncOpenAI):
        self.client = openai_client
    
    async def transcribe(
        self,
        audio_file_url: str,
        language: str = "pt"
    ) -> TranscriptionResult:
        """
        Transcreve √°udio do WhatsApp.
        
        SEMPRE executa antes do pipeline se message_type == "audio".
        """
        # Implementar conforme spec
        pass
    
    async def _download_audio(self, url: str) -> bytes:
        """Download do √°udio via WhatsApp Media API."""
        # Implementar com httpx + auth token
        pass
    
    def _estimate_confidence(self, whisper_response) -> float:
        """Estima confian√ßa baseado em palavras reconhecidas."""
        # Heur√≠stica: % palavras com >3 letras
        pass
```

**Checklist:**

- [ ] Criar `src/ai/services/transcription_agent.py`
- [ ] Implementar `TranscriptionAgent.transcribe()`
- [ ] Integrar Whisper API (modelo `whisper-1`)
- [ ] Implementar download de √°udio:
    - [ ] Usar `httpx.AsyncClient`
    - [ ] Auth com WhatsApp token (ler de `settings.whatsapp.media_token`)
    - [ ] Timeout 30s
- [ ] Adicionar fallback se transcri√ß√£o falha:

```python
return TranscriptionResult(
    text="[√Åudio n√£o p√¥de ser transcrito]",
    language=language,
    duration_seconds=0,
    confidence=0.0,
    error=str(e)
)
```

- [ ] Logging estruturado:

```python
logger.info("audio_transcribed", extra={
    "duration_seconds": result.duration_seconds,
    "text_length": len(result.text),
    "confidence": result.confidence,
    "cost_usd": result.duration_seconds * 0.006 / 60
})
```

- [ ] Testar com √°udio real (mock opcional para CI)
- [ ] Arquivo ‚â§ 200 linhas
- [ ] Commit: `feat(ai): add TranscriptionAgent with Whisper API`

---

### 2.3 ContextInjector üéØ **CORE DA REFATORA√á√ÉO**

**Objetivo:** Injetar contexto din√¢mico por vertente Pyloto

**Arquivos:**

1. `src/ai/contexts/pyloto_verticals.py` (contextos das vertentes)
2. `src/ai/services/context_injector.py` (l√≥gica de inje√ß√£o)

**Implementa√ß√£o:**

**Arquivo 1:** `src/ai/contexts/pyloto_verticals.py`

```python
"""
Contextos detalhados das vertentes Pyloto.

Cada vertente tem:
- Descri√ß√£o
- P√∫blico-alvo
- Pricing (ranges, n√£o valores exatos)
- Features principais
- Use cases
- Cases de sucesso
- Obje√ß√µes comuns + respostas
- Pr√≥ximos passos
- FAQ

Conformidade REGRAS_E_PADROES.md:
- ¬ß 1.1: Clareza > esperteza (texto direto, sem jarg√£o)
- ¬ß 4: Dividir em m√∫ltiplos arquivos se > 200 linhas cada contexto
"""

from dataclasses import dataclass
from typing import Literal

VerticalType = Literal[
    "saas", "sob_medida", "gestao_perfis",
    "trafego_pago", "automacao_atendimento", "intermediacao"
]

@dataclass
class VerticalContext:
    vertical: VerticalType
    description: str
    target_audience: str
    pricing: str
    features: list[str]
    use_cases: list[str]
    success_stories: list[str]
    common_objections: dict[str, str]
    next_steps: list[str]
    faq: dict[str, str]
    
    def to_prompt_context(self) -> str:
        """Converte para texto formatado (inje√ß√£o no prompt)."""
        # Implementar formata√ß√£o estruturada
        pass

# Inst√¢ncias dos contextos
SAAS_CONTEXT = VerticalContext(...)
SOB_MEDIDA_CONTEXT = VerticalContext(...)
GESTAO_PERFIS_CONTEXT = VerticalContext(...)
TRAFEGO_PAGO_CONTEXT = VerticalContext(...)
AUTOMACAO_ATENDIMENTO_CONTEXT = VerticalContext(...)
INTERMEDIACAO_CONTEXT = VerticalContext(...)
```

**Arquivo 2:** `src/ai/services/context_injector.py`

```python
"""
Injeta contexto din√¢mico baseado em LeadContact.primary_interest.

Responsabilidades:
- Ler LeadContact.primary_interest
- Carregar contexto vertical relevante
- Combinar CORE + VERTICAL
- Ajustar por conversation_stage (discovery, objection, closing)

Conformidade REGRAS_E_PADROES.md:
- ¬ß 1.2 SRP: √önica responsabilidade (context injection)
- ¬ß 3: N√£o importa de api/ (apenas app/protocols)
"""

from ai.contexts.pyloto_verticals import (
    SAAS_CONTEXT, SOB_MEDIDA_CONTEXT, # ... importar todos
)
from app.protocols.models import LeadContact
from typing import Literal
from config.logging import get_logger

logger = get_logger(__name__)

class ContextInjector:
    """Injeta contexto din√¢mico por vertente."""
    
    CORE_CONTEXT = """
    Voc√™ √© Otto, assistente virtual da Pyloto no WhatsApp.
    
    ## Sobre a Pyloto
    [Preencher com dados reais: endere√ßo, hor√°rio, contato]
    
    ## Vertentes de Servi√ßo
    [Lista resumida das 6 vertentes]
    """
    
    def __init__(self):
        self.vertical_contexts = {
            "saas": SAAS_CONTEXT,
            # ... mapear todos
        }
    
    def inject(
        self,
        lead_contact: LeadContact,
        conversation_stage: Literal["discovery", "qualification", "objection", "closing"]
    ) -> str:
        """Injeta contexto baseado em LeadContact.primary_interest."""
        # Implementar l√≥gica conforme spec
        pass
```

**Checklist:**

- [ ] Criar `src/ai/contexts/` (novo diret√≥rio)
- [ ] Criar `src/ai/contexts/__init__.py` (exports)
- [ ] Criar `src/ai/contexts/pyloto_verticals.py`
- [ ] Preencher `CORE_CONTEXT` com dados reais Pyloto:
    - [ ] Endere√ßo f√≠sico
    - [ ] Hor√°rio de funcionamento
    - [ ] Telefone/WhatsApp de contato
    - [ ] Email
- [ ] Implementar 6 contextos verticais:
    - [ ] `SAAS_CONTEXT` (cl√≠nicas, academias, sal√µes)
    - [ ] `SOB_MEDIDA_CONTEXT` (desenvolvimento custom)
    - [ ] `GESTAO_PERFIS_CONTEXT` (redes sociais)
    - [ ] `TRAFEGO_PAGO_CONTEXT` (Google/Meta Ads)
    - [ ] `AUTOMACAO_ATENDIMENTO_CONTEXT` (chatbots IA)
    - [ ] `INTERMEDIACAO_CONTEXT` (marketplace servi√ßos)
- [ ] Cada contexto deve ter:
    - [ ] Descri√ß√£o (2-3 par√°grafos)
    - [ ] Pricing (ranges, ex: "a partir de R\$ 159/m√™s")
    - [ ] 5-8 features principais
    - [ ] 3-5 use cases
    - [ ] 2-3 cases de sucesso (anonimizados se necess√°rio)
    - [ ] 5+ obje√ß√µes comuns + respostas
    - [ ] 4 pr√≥ximos passos sugeridos
    - [ ] Top 5 FAQ
- [ ] Garantir cada contexto ‚â§ 800 tokens quando convertido
- [ ] Criar `src/ai/services/context_injector.py`
- [ ] Implementar `ContextInjector.inject()`
- [ ] Adicionar logging:

```python
logger.debug("context_injected", extra={
    "vertical": lead_contact.primary_interest,
    "conversation_stage": conversation_stage,
    "tokens_estimate": len(context.split()) * 1.3
})
```

- [ ] Testar cada contexto individualmente
- [ ] Verificar se arquivos ‚â§ 200 linhas (dividir se necess√°rio)
- [ ] Commit: `feat(ai): add context injection system with vertical contexts`

---

## FASE 3: OTTOAGENT (Dias 5-6)

### 3.1 Reescrever Orchestrator como OttoAgent ‚úÖ

**Objetivo:** Agente √∫nico que decide estado + gera resposta + escolhe tipo mensagem

**Arquivo:** `src/ai/services/otto_agent.py` (renomear de `orchestrator.py`)

**Implementa√ß√£o:**

```python
"""
OttoAgent - Agente √∫nico de decis√£o e resposta.

Responsabilidades:
- Receber LeadContact j√° preenchido (por ExtractionAgent)
- Receber contexto din√¢mico (por ContextInjector)
- Decidir pr√≥ximo estado FSM
- Gerar resposta natural
- Escolher tipo de mensagem (text/button/list)
- Retornar decis√£o estruturada (OttoDecision)

Conformidade REGRAS_E_PADROES.md:
- ¬ß 1.2 SRP: Decis√£o + Resposta (acopladas por natureza)
- ¬ß 4: Arquivo ‚â§ 200 linhas
- ¬ß 5: Type hints completos
- ¬ß 6: Logs estruturados
- ¬ß 7: Structured outputs (n√£o free-text parsing)
"""

from pydantic import BaseModel, Field
from openai import AsyncOpenAI
from typing import Literal
from app.protocols.models import LeadContact, Session
from fsm.states.session import SessionState
from fsm.transitions.rules import VALID_TRANSITIONS
from ai.services.context_injector import ContextInjector
from config.logging import get_logger

logger = get_logger(__name__)

class OttoDecision(BaseModel):
    """Output estruturado do OttoAgent (structured output garantido)."""
    
    next_state: Literal[
        "INITIAL", "TRIAGE", "COLLECTING_INFO",
        "GENERATING_RESPONSE", "HANDOFF_HUMAN",
        "SELF_SERVE_INFO", "SCHEDULED_FOLLOWUP",
        "ROUTE_EXTERNAL", "TIMEOUT", "ERROR"
    ]
    
    response_text: str = Field(max_length=500)
    
    message_type: Literal["text", "interactive_button", "interactive_list"]
    
    confidence: float = Field(ge=0.0, le=1.0)
    
    reasoning: str = Field(
        description="Justificativa da decis√£o (debug/logs)"
    )
    
    requires_human: bool = False

class OttoAgent:
    """Agente √∫nico Otto."""
    
    def __init__(
        self,
        openai_client: AsyncOpenAI,
        context_injector: ContextInjector
    ):
        self.client = openai_client
        self.injector = context_injector
        self.model = "gpt-4o-2024-08-06"  # Structured outputs support
    
    async def process_message(
        self,
        user_input: str,
        session: Session,
        current_state: SessionState
    ) -> OttoDecision:
        """Processa mensagem e retorna decis√£o estruturada."""
        
        lead = session.lead_contact
        
        # 1. Detecta conversation_stage
        stage = self._detect_conversation_stage(session, user_input, lead)
        
        # 2. Injeta contexto din√¢mico
        dynamic_context = self.injector.inject(
            lead_contact=lead,
            conversation_stage=stage
        )
        
        # 3. Monta prompt
        system_prompt = self._build_prompt(
            dynamic_context, lead, session, current_state
        )
        
        # 4. Chama LLM com structured output
        response = await self.client.beta.chat.completions.parse(
            model=self.model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_input}
            ],
            response_format=OttoDecision,
            temperature=0.7,
            max_tokens=800
        )
        
        decision: OttoDecision = response.choices.message.parsed
        
        # 5. Valida FSM transition
        if not self._is_valid_transition(current_state, decision.next_state):
            logger.warning("invalid_fsm_transition", extra={
                "from": current_state.value,
                "to": decision.next_state
            })
            decision.next_state = current_state.value
            decision.requires_human = True
        
        # 6. Log
        logger.info("otto_decision", extra={
            "next_state": decision.next_state,
            "confidence": decision.confidence,
            "lead_score": lead.qualification_score,
            "conversation_stage": stage,
            "tokens": response.usage.total_tokens,
            "cost_usd": response.usage.total_tokens * 0.0000025
        })
        
        return decision
    
    def _detect_conversation_stage(
        self, session: Session, user_input: str, lead: LeadContact
    ) -> Literal["discovery", "qualification", "objection", "closing"]:
        """Detecta est√°gio baseado em LeadContact e input."""
        # Implementar l√≥gica conforme spec
        pass
    
    def _build_prompt(
        self, context: str, lead: LeadContact, 
        session: Session, state: SessionState
    ) -> str:
        """Monta prompt completo."""
        # Implementar conforme spec
        pass
    
    def _is_valid_transition(
        self, current: SessionState, next_state: str
    ) -> bool:
        """Valida se transi√ß√£o FSM √© permitida."""
        try:
            next_enum = SessionState[next_state]
            return next_enum in VALID_TRANSITIONS.get(current, set())
        except KeyError:
            return False
```

**Checklist:**

- [ ] Renomear `src/ai/services/orchestrator.py` ‚Üí `otto_agent.py`
- [ ] Deletar `_orchestrator_helpers.py` (n√£o mais necess√°rio)
- [ ] Criar `OttoDecision` (Pydantic BaseModel)
- [ ] Implementar `OttoAgent.__init__()`
- [ ] Implementar `OttoAgent.process_message()`
- [ ] Implementar `_detect_conversation_stage()`:
    - [ ] Discovery: score < 30
    - [ ] Qualification: score 30-59
    - [ ] Objection: keywords de obje√ß√£o
    - [ ] Closing: score >= 60 + sinais de interesse
- [ ] Implementar `_build_prompt()`:
    - [ ] Combinar: context + LeadContact summary + history + FSM state
    - [ ] Max 2.500 tokens total
- [ ] Implementar `_is_valid_transition()` (usa VALID_TRANSITIONS do FSM)
- [ ] Adicionar fallback se LLM falha:

```python
except Exception as e:
    logger.error("otto_failed", exc_info=e)
    return OttoDecision(
        next_state=SessionState.HANDOFF_HUMAN.value,
        response_text="Desculpe, tive um problema. Conectando com a equipe...",
        message_type="text",
        confidence=0.0,
        reasoning=f"LLM failure: {e}",
        requires_human=True
    )
```

- [ ] Garantir arquivo ‚â§ 200 linhas (extrair helpers se necess√°rio)
- [ ] Atualizar `src/ai/__init__.py` (exportar `OttoAgent`, remover antigos)
- [ ] Executar `ruff check src/ai/services/otto_agent.py`
- [ ] Commit: `refactor(ai): rewrite orchestrator as OttoAgent (single agent)`

---

### 3.2 ValidationPipeline (H√≠brido) ‚úÖ

**Objetivo:** Valida√ß√£o em 3 gates (determin√≠stico + confidence + LLM seletivo)

**Arquivo:** `src/ai/services/decision_validator.py`

**Implementa√ß√£o:**

```python
"""
Pipeline de valida√ß√£o h√≠brido para decis√µes do OttoAgent.

Gates:
1. Determin√≠stico (sempre): FSM v√°lida, PII, promessas proibidas
2. Confidence check: >= 0.85 aprova, < 0.7 escala, 0.7-0.85 ‚Üí Gate 3
3. LLM review (seletivo): Valida apenas zona cinza

Conformidade REGRAS_E_PADROES.md:
- ¬ß 1.3: Determinismo (Gate 1 √© 100% determin√≠stico)
- ¬ß 4: Arquivo ‚â§ 200 linhas
- ¬ß 7: Defesa em profundidade (m√∫ltiplas camadas)
"""

from enum import Enum
from dataclasses import dataclass
from openai import AsyncOpenAI
from ai.services.otto_agent import OttoDecision
from app.protocols.models import Session
from fsm.states.session import SessionState
from fsm.transitions.rules import VALID_TRANSITIONS
from config.logging import get_logger
import re

logger = get_logger(__name__)

class ValidationType(Enum):
    DETERMINISTIC = "deterministic"
    LLM_LIGHTWEIGHT = "llm_lightweight"
    HUMAN_REQUIRED = "human"

@dataclass
class ValidationResult:
    approved: bool
    validation_type: ValidationType
    corrections: dict[str, any] | None = None
    reasoning: str = ""
    cost_usd: float = 0.0

class DecisionValidator:
    """Pipeline de valida√ß√£o h√≠brido."""
    
    HIGH_CONFIDENCE_THRESHOLD = 0.85
    LOW_CONFIDENCE_THRESHOLD = 0.70
    
    def __init__(self, openai_client: AsyncOpenAI):
        self.client = openai_client
    
    async def validate(
        self,
        decision: OttoDecision,
        session: Session,
        current_state: SessionState
    ) -> ValidationResult:
        """3-gate validation system."""
        
        # GATE 1: Determin√≠stico (sempre)
        gate1 = self._validate_deterministic(decision, session, current_state)
        if not gate1.approved:
            return gate1
        
        # GATE 2: Confidence check
        if decision.confidence >= self.HIGH_CONFIDENCE_THRESHOLD:
            return ValidationResult(
                approved=True,
                validation_type=ValidationType.DETERMINISTIC,
                reasoning=f"High confidence ({decision.confidence:.2f})"
            )
        
        if decision.confidence < self.LOW_CONFIDENCE_THRESHOLD:
            return ValidationResult(
                approved=False,
                validation_type=ValidationType.HUMAN_REQUIRED,
                reasoning=f"Low confidence ({decision.confidence:.2f})"
            )
        
        # GATE 3: LLM review (apenas 0.7-0.85)
        return await self._validate_llm_lightweight(decision, session)
    
    def _validate_deterministic(
        self, decision: OttoDecision, session: Session, 
        current_state: SessionState
    ) -> ValidationResult:
        """Gate 1: Valida√ß√µes determin√≠sticas."""
        # Implementar checks conforme spec
        pass
    
    async def _validate_llm_lightweight(
        self, decision: OttoDecision, session: Session
    ) -> ValidationResult:
        """Gate 3: Valida√ß√£o leve com gpt-4o-mini."""
        # Implementar conforme spec
        pass
```

**Checklist:**

- [ ] Criar `src/ai/services/decision_validator.py`
- [ ] Implementar `ValidationResult` (dataclass)
- [ ] Implementar `DecisionValidator.validate()`
- [ ] Implementar `_validate_deterministic()`:
    - [ ] Check FSM transition v√°lida
    - [ ] Check response length < 1000 chars
    - [ ] Check PII sens√≠vel (CPF, cart√£o): regex
    - [ ] Check promessas proibidas: ["agendei", "confirmei", "enviei"]
    - [ ] Check coer√™ncia message_type (button precisa ter op√ß√µes no texto)
- [ ] Implementar `_validate_llm_lightweight()`:
    - [ ] Usar `gpt-4o-mini` (barato)
    - [ ] Prompt de valida√ß√£o (1 linha: APPROVED/REJECTED)
    - [ ] Timeout 10s
- [ ] Adicionar thresholds configur√°veis:

```python
# Em src/config/settings/ai/validation.py
HIGH_CONFIDENCE_THRESHOLD = 0.85
LOW_CONFIDENCE_THRESHOLD = 0.70
```

- [ ] Logging por gate:

```python
logger.info("gate1_deterministic", extra={"approved": result.approved})
logger.info("gate2_confidence", extra={"threshold_crossed": "high"})
logger.info("gate3_llm_review", extra={"cost_usd": result.cost_usd})
```

- [ ] Arquivo ‚â§ 200 linhas
- [ ] Commit: `feat(ai): add hybrid validation pipeline (3-gate)`

---

## FASE 4: ATUALIZAR LeadContact (Dia 7)

### 4.1 Expandir LeadContact Model ‚úÖ

**Objetivo:** LeadContact como single source of truth do lead

**Arquivo:** `src/app/protocols/models.py` (atualizar existente)

**Implementa√ß√£o:**

```python
# Adicionar ao arquivo existente

class LeadContact(BaseModel):
    """
    Perfil do lead, preenchido progressivamente pelo ExtractionAgent.
    
    Esta classe √© sempre carregada no prompt do Otto.
    """
    
    # Identifica√ß√£o
    name: str | None = None
    email: str | None = None
    phone: str | None = None
    company: str | None = None
    role: str | None = None
    location: str | None = None
    
    # Interesse (CR√çTICO para context injection)
    primary_interest: Literal[
        "saas", "sob_medida", "gestao_perfis",
        "trafego_pago", "automacao_atendimento", "intermediacao"
    ] | None = None
    
    secondary_interests: list[str] = Field(default_factory=list)
    
    # Qualifica√ß√£o
    urgency: Literal["low", "medium", "high", "urgent"] | None = None
    budget_indication: str | None = None
    specific_need: str | None = Field(None, max_length=150)
    company_size: Literal["mei", "micro", "pequena", "media", "grande"] | None = None
    
    # Scores
    qualification_score: float = Field(default=0.0, ge=0.0, le=100.0)
    is_qualified: bool = False
    
    # Metadados
    first_contact_at: datetime | None = None
    last_updated_at: datetime | None = None
    total_messages: int = 0
    
    # Flags
    requested_human: bool = False
    showed_objection: bool = False
    
    def to_prompt_summary(self) -> str:
        """Converte para texto resumido (max 200 tokens)."""
        # Implementar conforme spec
        pass
    
    def calculate_qualification_score(self) -> float:
        """
        Calcula score 0-100 baseado em campos preenchidos.
        
        Crit√©rios:
        - Nome: +15
        - Contato: +15
        - Empresa: +10
        - Interesse: +20
        - Necessidade: +15
        - Urg√™ncia alta: +15
        - Budget: +10
        """
        # Implementar conforme spec
        pass
```

**Checklist:**

- [ ] Adicionar novos campos em `LeadContact`
- [ ] Implementar `to_prompt_summary()`:
    - [ ] Formato conciso (bullet points)
    - [ ] Max 200 tokens
    - [ ] Destacar campos cr√≠ticos (interesse, urg√™ncia)
- [ ] Implementar `calculate_qualification_score()`:
    - [ ] Score 0-100
    - [ ] `is_qualified = score >= 60`
    - [ ] Atualizar `self.qualification_score` e `self.is_qualified`
- [ ] Adicionar valida√ß√µes Pydantic:
    - [ ] Email: `Field(..., pattern=r'^[^@]+@[^@]+\.[^@]+$')`
    - [ ] Phone: `Field(..., pattern=r'^\(\d{2}\) 9?\d{4}-?\d{4}$')`
- [ ] Executar `ruff check src/app/protocols/models.py`
- [ ] Commit: `feat(app): expand LeadContact model with qualification scoring`

---

### 4.2 Merge Strategy (ExtractionAgent ‚Üí LeadContact) ‚úÖ

**Objetivo:** L√≥gica de merge inteligente (n√£o sobrescrever dados anteriores)

**Arquivo:** `src/app/use_cases/whatsapp/_inbound_helpers.py` (criar helper)

**Implementa√ß√£o:**

```python
"""
Helpers para merge de extracted info em LeadContact.

Conformidade REGRAS_E_PADROES.md:
- ¬ß 4: Arquivo ‚â§ 200 linhas
- ¬ß 5: Type hints completos
"""

from app.protocols.models import LeadContact
from ai.services.extraction_agent import ExtractedLeadInfo
from config.logging import get_logger

logger = get_logger(__name__)

def merge_extracted_info(
    lead: LeadContact,
    extracted: ExtractedLeadInfo
) -> LeadContact:
    """
    Merge extracted info em LeadContact.
    
    Estrat√©gia:
    - Campos de identifica√ß√£o: n√£o sobrescrever (primeira captura vale)
    - Interesse: atualizar se mais espec√≠fico
    - Urg√™ncia: sempre atualizar (pode mudar)
    - Necessidade: append (n√£o sobrescrever)
    """
    
    # Identifica√ß√£o (s√≥ preenche se vazio)
    if extracted.name and not lead.name:
        lead.name = extracted.name
        logger.info("lead_name_captured", extra={"name": extracted.name})
    
    # ... implementar resto
    
    # Recalcula score
    lead.calculate_qualification_score()
    
    return lead
```

**Checklist:**

- [ ] Criar `src/app/use_cases/whatsapp/_inbound_helpers.py`
- [ ] Implementar `merge_extracted_info()`:
    - [ ] Nome: primeira captura (n√£o sobrescreve)
    - [ ] Email: primeira captura
    - [ ] Phone: primeira captura
    - [ ] Company: primeira captura
    - [ ] Interesse prim√°rio: primeira captura, novos viram secund√°rios
    - [ ] Urg√™ncia: sempre atualiza (pode aumentar/diminuir)
    - [ ] Necessidade: append com ";" (max 150 chars)
    - [ ] Budget: atualiza se fornecido
- [ ] Logging estruturado para cada captura
- [ ] Chamar `lead.calculate_qualification_score()` ao final
- [ ] Arquivo ‚â§ 200 linhas
- [ ] Commit: `feat(app): add merge strategy for extracted lead info`

---

## FASE 5: INTEGRA√á√ÉO NO USE CASE (Dia 8)

### 5.1 Reescrever ProcessInboundCanonicalUseCase ‚úÖ

**Objetivo:** Integrar Otto + agentes utilit√°rios + valida√ß√£o

**Arquivo:** `src/app/use_cases/whatsapp/process_inbound_canonical.py`

**Implementa√ß√£o:**

```python
"""
Use case can√¥nico de processamento de mensagem inbound.

Pipeline:
1. Fast-path (70% dos casos, 0 LLMs)
2. Transcri√ß√£o (se √°udio)
3. Parallel: Otto + Extraction
4. Merge extracted ‚Üí LeadContact
5. Validation (3-gate)
6. Update session
7. Return command

Conformidade REGRAS_E_PADROES.md:
- ¬ß 1.2 SRP: Orquestra√ß√£o do pipeline (n√£o l√≥gica de neg√≥cio)
- ¬ß 4: Arquivo ‚â§ 200 linhas
"""

import asyncio
from app.protocols.models import InboundEvent, OutboundCommand, Session
from ai.services.otto_agent import OttoAgent
from ai.services.extraction_agent import ExtractionAgent
from ai.services.transcription_agent import TranscriptionAgent
from ai.services.decision_validator import DecisionValidator
from app.use_cases.whatsapp._inbound_helpers import merge_extracted_info
from config.logging import get_logger

logger = get_logger(__name__)

class ProcessInboundCanonicalUseCase:
    """Use case de processamento de mensagem inbound."""
    
    def __init__(
        self,
        otto_agent: OttoAgent,
        extraction_agent: ExtractionAgent,
        transcription_agent: TranscriptionAgent,
        decision_validator: DecisionValidator,
        session_manager: SessionManager,
    ):
        self.otto = otto_agent
        self.extraction = extraction_agent
        self.transcription = transcription_agent
        self.validator = decision_validator
        self.sessions = session_manager
    
    async def execute(self, event: InboundEvent) -> OutboundCommand:
        """Pipeline completo."""
        
        # 1. Load session
        session = await self.sessions.resolve_or_create(event.sender_id)
        
        # 2. Transcri√ß√£o (se √°udio)
        if event.message_type == "audio":
            # Implementar conforme spec
            pass
        
        # 3. Fast-path
        fast_result = self._classify_fast_path(event.message_text)
        if fast_result:
            return OutboundCommand(text=fast_result.response, message_type="text")
        
        # 4. Parallel: Otto + Extraction
        decision, extracted = await asyncio.gather(
            self.otto.process_message(
                user_input=event.message_text,
                session=session,
                current_state=session.current_state
            ),
            self.extraction.extract(
                user_message=event.message_text,
                conversation_context=session.history[-3:]
            )
        )
        
        # 5. Merge extracted ‚Üí LeadContact
        session.lead_contact = merge_extracted_info(
            lead=session.lead_contact,
            extracted=extracted
        )
        
        # 6. Validation (3-gate)
        validation = await self.validator.validate(
            decision=decision,
            session=session,
            current_state=session.current_state
        )
        
        if not validation.approved:
            # Implementar handling de rejei√ß√£o
            pass
        
        # 7. Update session
        session.current_state = decision.next_state
        session.add_to_history(event.message_text, role="user")
        session.add_to_history(decision.response_text, role="assistant")
        await self.sessions.save(session)
        
        # 8. Return
        return OutboundCommand(
            text=decision.response_text,
            message_type=decision.message_type,
            next_state=decision.next_state
        )
```

**Checklist:**

- [ ] Reescrever `execute()` com novo pipeline
- [ ] Implementar fast-path (regex para sauda√ß√µes/FAQs):

```python
def _classify_fast_path(self, text: str) -> FastPathResult | None:
    if re.match(r"^(oi|ol√°|bom dia)", text.lower()):
        return FastPathResult(response="Oi! Como posso ajudar?")
    # ... mais regras
    return None
```

- [ ] Integrar TranscriptionAgent:

```python
if event.message_type == "audio":
    transcription = await self.transcription.transcribe(event.media_url)
    if transcription.confidence < 0.6:
        return OutboundCommand(text="N√£o consegui entender o √°udio...")
    event.message_text = transcription.text
```

- [ ] Paralelizar Otto + Extraction:

```python
decision, extracted = await asyncio.gather(
    self.otto.process_message(...),
    self.extraction.extract(...)
)
```

- [ ] Merge extracted info
- [ ] Validar com ValidationPipeline
- [ ] Handling de valida√ß√£o rejeitada:
    - [ ] Se HUMAN_REQUIRED: escalar
    - [ ] Se corrections: aplicar e logar
- [ ] Notificar time se lead qualificar:

```python
if lead.is_qualified and not session.metadata.get("notified"):
    await self.notify_qualified_lead(lead, session)
    session.metadata["notified"] = True
```

- [ ] Logging estruturado de m√©tricas:

```python
logger.info("pipeline_completed", extra={
    "lead_score": lead.qualification_score,
    "is_qualified": lead.is_qualified,
    "validation_type": validation.validation_type.value,
    "total_cost_usd": # calcular
})
```

- [ ] Arquivo ‚â§ 200 linhas (extrair helpers se necess√°rio)
- [ ] Executar `ruff check src/app/use_cases/whatsapp/`
- [ ] Commit: `refactor(app): rewrite use case with Otto + utilities pipeline`

---

### 5.2 Atualizar Bootstrap (Wiring) ‚úÖ

**Objetivo:** Instanciar novos agentes e injetar depend√™ncias

**Arquivo:** `src/app/bootstrap/whatsapp_factory.py`

**Implementa√ß√£o:**

```python
"""
Factory de componentes WhatsApp.

Conformidade REGRAS_E_PADROES.md:
- ¬ß 3: √önico lugar para wiring (bootstrap)
"""

from openai import AsyncOpenAI
from ai.services.otto_agent import OttoAgent
from ai.services.extraction_agent import ExtractionAgent
from ai.services.transcription_agent import TranscriptionAgent
from ai.services.context_injector import ContextInjector
from ai.services.decision_validator import DecisionValidator
from app.use_cases.whatsapp.process_inbound_canonical import (
    ProcessInboundCanonicalUseCase
)
from config.settings.ai.openai import OpenAISettings

def create_whatsapp_use_case() -> ProcessInboundCanonicalUseCase:
    """Cria use case com todas depend√™ncias."""
    
    # OpenAI client
    openai_settings = OpenAISettings()
    openai_client = AsyncOpenAI(api_key=openai_settings.api_key)
    
    # Agentes utilit√°rios
    extraction_agent = ExtractionAgent(openai_client)
    transcription_agent = TranscriptionAgent(openai_client)
    context_injector = ContextInjector()
    
    # Otto (agente principal)
    otto_agent = OttoAgent(
        openai_client=openai_client,
        context_injector=context_injector
    )
    
    # Validator
    decision_validator = DecisionValidator(openai_client)
    
    # Session manager (existente)
    session_manager = create_session_manager()
    
    # Use case
    return ProcessInboundCanonicalUseCase(
        otto_agent=otto_agent,
        extraction_agent=extraction_agent,
        transcription_agent=transcription_agent,
        decision_validator=decision_validator,
        session_manager=session_manager
    )
```

**Checklist:**

- [ ] Atualizar `src/app/bootstrap/whatsapp_factory.py`
- [ ] Remover instancia√ß√µes de agentes antigos:
    - [ ] StateAgent
    - [ ] ResponseAgent
    - [ ] MessageTypeAgent
    - [ ] DecisionAgent
    - [ ] AIOrchestrator (antigo)
- [ ] Adicionar instancia√ß√µes de novos componentes:
    - [ ] ExtractionAgent
    - [ ] TranscriptionAgent
    - [ ] ContextInjector
    - [ ] OttoAgent
    - [ ] DecisionValidator
- [ ] Atualizar `create_whatsapp_use_case()`
- [ ] Executar `ruff check src/app/bootstrap/`
- [ ] Commit: `refactor(app): update bootstrap with new Otto architecture`

---

## FASE 6: TESTES (Dias 9-10)

### 6.1 Testes Unit√°rios dos Agentes Utilit√°rios ‚úÖ

**Arquivos de teste:**

1. `tests/test_ai/test_extraction_agent.py`
2. `tests/test_ai/test_transcription_agent.py`
3. `tests/test_ai/test_context_injector.py`
4. `tests/test_ai/test_otto_agent.py`
5. `tests/test_ai/test_decision_validator.py`

**Checklist:**

- [ ] Criar `tests/test_ai/test_extraction_agent.py`:
    - [ ] Test: extrai nome corretamente
    - [ ] Test: extrai email v√°lido
    - [ ] Test: detecta service_interest (saas, sob_medida, etc)
    - [ ] Test: detecta urg√™ncia (keywords: urgente, hoje, etc)
    - [ ] Test: retorna confidence score
    - [ ] Test: fallback se LLM falha
- [ ] Criar `tests/test_ai/test_transcription_agent.py`:
    - [ ] Test: transcreve √°udio mock (usar fixture)
    - [ ] Test: detecta idioma pt-BR
    - [ ] Test: fallback se download falha
    - [ ] Test: confidence estimation
- [ ] Criar `tests/test_ai/test_context_injector.py`:
    - [ ] Test: injeta SAAS_CONTEXT se primary_interest="saas"
    - [ ] Test: injeta SOB_MEDIDA_CONTEXT se primary_interest="sob_medida"
    - [ ] Test: injeta apenas CORE_CONTEXT se primary_interest=None
    - [ ] Test: modo discovery se lead n√£o qualificado
    - [ ] Test: modo objection se conversation_stage="objection"
- [ ] Criar `tests/test_ai/test_otto_agent.py`:
    - [ ] Test: retorna OttoDecision v√°lido
    - [ ] Test: detecta conversation_stage="discovery" se score < 30
    - [ ] Test: detecta conversation_stage="closing" se qualificado + interesse
    - [ ] Test: valida FSM transition antes de retornar
    - [ ] Test: fallback se LLM falha
- [ ] Criar `tests/test_ai/test_decision_validator.py`:
    - [ ] Test: Gate 1 rejeita FSM inv√°lida
    - [ ] Test: Gate 1 rejeita PII sens√≠vel (CPF)
    - [ ] Test: Gate 1 rejeita promessas proibidas
    - [ ] Test: Gate 2 aprova se confidence >= 0.85
    - [ ] Test: Gate 2 escala se confidence < 0.7
    - [ ] Test: Gate 3 chama LLM se 0.7 <= confidence < 0.85
- [ ] Executar `pytest tests/test_ai/ -v`
- [ ] Garantir cobertura >= 80% nos novos arquivos:

```bash
pytest tests/test_ai/ --cov=src/ai/services --cov-report=term
```

- [ ] Commit: `test(ai): add comprehensive tests for Otto architecture`

---

### 6.2 Testes de Integra√ß√£o (Use Case) ‚úÖ

**Arquivo:** `tests/app/use_cases/whatsapp/test_process_inbound_canonical_v2.py`

**Cen√°rios de teste:**

1. **Fast-path**: Sauda√ß√£o simples ‚Üí resposta determin√≠stica
2. **√Åudio**: Transcri√ß√£o ‚Üí Otto processa
3. **Primeira intera√ß√£o**: Sem dados ‚Üí Otto coleta nome
4. **Qualifica√ß√£o progressiva**: Nome ‚Üí empresa ‚Üí interesse ‚Üí qualificado
5. **Obje√ß√£o**: Lead levanta obje√ß√£o de pre√ßo ‚Üí Otto consulta contexto
6. **Escala√ß√£o**: Confian√ßa baixa ‚Üí escala para humano
7. **Valida√ß√£o**: Decis√£o inv√°lida ‚Üí corre√ß√£o autom√°tica

**Checklist:**

- [ ] Criar `tests/app/use_cases/whatsapp/test_process_inbound_canonical_v2.py`
- [ ] Implementar fixtures:
    - [ ] Mock OpenAI client (respostas canned)
    - [ ] Mock SessionManager (in-memory)
    - [ ] Mock WhatsApp Media API (para transcription)
- [ ] Implementar 7 cen√°rios de teste
- [ ] Testar m√©tricas s√£o logadas corretamente
- [ ] Testar LeadContact.qualification_score atualiza
- [ ] Testar notifica√ß√£o de lead qualificado
- [ ] Executar `pytest tests/app/use_cases/ -v`
- [ ] Garantir cobertura >= 70% no use case
- [ ] Commit: `test(app): add integration tests for Otto pipeline`

---

### 6.3 Testes E2E (Opcional, mas recomendado) ‚úÖ

**Objetivo:** Testar fluxo completo com API real (staging)

**Arquivo:** `tests/e2e/test_otto_conversation_flow.py`

**Cen√°rios:**

1. Conversa completa: Oi ‚Üí Nome ‚Üí Empresa ‚Üí Interesse SaaS ‚Üí Qualificado
2. Conversa com √°udio: Envio √°udio ‚Üí Transcri√ß√£o ‚Üí Resposta
3. Obje√ß√£o tratada: Interesse ‚Üí Obje√ß√£o pre√ßo ‚Üí Case de sucesso ‚Üí Agendar demo

**Checklist (opcional):**

- [ ] Criar `tests/e2e/test_otto_conversation_flow.py`
- [ ] Usar WhatsApp Test Number (sandbox)
- [ ] Implementar 3 cen√°rios E2E
- [ ] Executar apenas em staging: `pytest tests/e2e/ -v -m staging`
- [ ] Validar m√©tricas no dashboard (custo, lat√™ncia, qualifica√ß√£o)
- [ ] Commit: `test(e2e): add conversation flow tests`

---

## FASE 7: DOCUMENTA√á√ÉO E DEPLOY (Dia 10)

### 7.1 Atualizar Documenta√ß√£o ‚úÖ

**Arquivos a atualizar:**

1. `README.md` (overview da arquitetura)
2. `AUDITORIA_ARQUITETURA.md` (refletir nova estrutura)
3. `docs/OTTO_ARCHITECTURE.md` (novo, detalhamento t√©cnico)

**Checklist:**

- [ ] Atualizar `README.md`:
    - [ ] Se√ß√£o "Arquitetura" com diagrama Otto
    - [ ] Listar agentes utilit√°rios
    - [ ] Atualizar m√©tricas (custo, lat√™ncia)
- [ ] Atualizar `AUDITORIA_ARQUITETURA.md`:
    - [ ] Marcar pipeline de 4 agentes como "REMOVIDO"
    - [ ] Adicionar se√ß√£o "Otto Architecture"
    - [ ] Atualizar m√©tricas de cobertura de testes
- [ ] Criar `docs/OTTO_ARCHITECTURE.md`:
    - [ ] Diagrama de fluxo completo
    - [ ] Especifica√ß√£o de cada agente
    - [ ] Context injection strategy
    - [ ] Validation pipeline (3-gate)
    - [ ] Exemplos de uso
- [ ] Atualizar `TODO_llm.md`:
    - [ ] Marcar itens conclu√≠dos
    - [ ] Adicionar novos itens (ex: fine-tuning, SentimentAgent)
- [ ] Commit: `docs: update architecture documentation for Otto`

---

### 7.2 Deploy em Staging ‚úÖ

**Objetivo:** Validar em ambiente real antes de produ√ß√£o

**Checklist:**

- [ ] Executar suite completa de testes localmente:

```bash
ruff check src/
pytest tests/ -v
pytest --cov=src --cov-report=term
```

- [ ] Verificar cobertura geral >= 55% (meta m√≠nima atual)
- [ ] Build Docker image:

```bash
docker build -t atende-pyloto:otto-v1 .
```

- [ ] Deploy no Google Cloud Run (staging):

```bash
gcloud run deploy atende-pyloto-staging \
  --image gcr.io/pyloto/atende-pyloto:otto-v1 \
  --region us-central1
```

- [ ] Configurar env vars:
    - [ ] `OPENAI_API_KEY`
    - [ ] `WHATSAPP_VERIFY_TOKEN`
    - [ ] `FIRESTORE_PROJECT_ID`
    - [ ] `REDIS_URL`
- [ ] Testar webhook WhatsApp:
    - [ ] Enviar "oi" ‚Üí receber resposta
    - [ ] Enviar √°udio ‚Üí verificar transcri√ß√£o
    - [ ] Enviar "preciso de sistema para cl√≠nica" ‚Üí verificar contexto SaaS injetado
- [ ] Monitorar logs (30min):

```bash
gcloud logging read "resource.type=cloud_run_revision AND resource.labels.service_name=atende-pyloto-staging" --limit 50
```

- [ ] Validar m√©tricas:
    - [ ] Custo m√©dio/msg: ~\$0.0003 (vs \$0.0009 antigo)
    - [ ] Lat√™ncia P95: < 3s
    - [ ] Taxa de qualifica√ß√£o: >= 20%
- [ ] Se tudo OK, commit: `deploy: Otto v1 to staging`

---

### 7.3 Rollout Produ√ß√£o (Cauteloso) ‚úÖ

**Objetivo:** Deploy gradual em produ√ß√£o

**Checklist:**

- [ ] Validar staging por 24-48h:
    - [ ] 0 erros cr√≠ticos
    - [ ] M√©tricas dentro do esperado
    - [ ] Feedback de usu√°rios teste positivo
- [ ] Criar feature flag (opcional):

```python
# Em settings
USE_OTTO_ARCHITECTURE = os.getenv("USE_OTTO", "false") == "true"
```

- [ ] Deploy produ√ß√£o com rollout gradual:
    - [ ] 10% tr√°fego ‚Üí Otto
    - [ ] 90% tr√°fego ‚Üí Pipeline antigo (fallback)
    - [ ] Monitorar 2h
    - [ ] Se OK: 50% tr√°fego
    - [ ] Monitorar 4h
    - [ ] Se OK: 100% tr√°fego
- [ ] Monitorar m√©tricas produ√ß√£o (72h):
    - [ ] Taxa de erro
    - [ ] Lat√™ncia
    - [ ] Custo LLM
    - [ ] Taxa de qualifica√ß√£o de leads
    - [ ] NPS/satisfa√ß√£o usu√°rio
- [ ] Se m√©tricas degradarem:
    - [ ] Rollback imediato para pipeline antigo
    - [ ] Investigar root cause
    - [ ] Corrigir em staging
    - [ ] Retry deploy
- [ ] Se m√©tricas melhorarem:
    - [ ] Deletar c√≥digo do pipeline antigo
    - [ ] Commit: `feat: Otto architecture fully deployed to production`
    - [ ] Atualizar vers√£o: `v2.0.0`

---

## M√âTRICAS DE SUCESSO

**Antes (Pipeline 4 Agentes):**

- Custo/msg: ~\$0.0009
- Lat√™ncia P95: ~3.5s
- Taxa qualifica√ß√£o: desconhecida
- Cobertura testes AI: 95%
- Manutenibilidade: m√©dia (complexo)

**Depois (Otto + Utilit√°rios) - Meta:**

- Custo/msg: ~\$0.0003 (-66%)
- Lat√™ncia P95: ~2.5s (-28%)
- Taxa qualifica√ß√£o: >= 20%
- Cobertura testes AI: >= 80%
- Manutenibilidade: alta (simples)

---

## ROLLBACK PLAN

Se algo der errado, execute:

```bash
# 1. Reverter para branch anterior
git checkout backup/4-agents-pipeline

# 2. Deploy staging/produ√ß√£o
gcloud run deploy atende-pyloto-staging --image [imagem anterior]

# 3. Investigar problema
# - Logs: gcloud logging read ...
# - M√©tricas: dashboard Firestore/BigQuery
# - Reproduzir localmente

# 4. Corrigir e retry
```


---

## ORDEM DE EXECU√á√ÉO RECOMENDADA

**Dia 1:** Fase 1 (Remo√ß√£o)
**Dia 2:** Fase 1 (Remo√ß√£o de testes)
**Dia 3:** Fase 2.1 (ExtractionAgent)
**Dia 4:** Fase 2.2 (TranscriptionAgent) + 2.3 (ContextInjector - in√≠cio)
**Dia 5:** Fase 2.3 (ContextInjector - conclus√£o) + 3.1 (OttoAgent - in√≠cio)
**Dia 6:** Fase 3.1 (OttoAgent - conclus√£o) + 3.2 (ValidationPipeline)
**Dia 7:** Fase 4 (LeadContact) + Fase 5.1 (Use Case)
**Dia 8:** Fase 5.2 (Bootstrap) + Fase 6.1 (Testes unit√°rios)
**Dia 9:** Fase 6.2 (Testes integra√ß√£o) + Fase 6.3 (E2E opcional)
**Dia 10:** Fase 7 (Documenta√ß√£o + Deploy staging)
**Dia 11+:** Monitoramento + Deploy produ√ß√£o gradual

---

## NOTAS IMPORTANTES

1. **Seguir REGRAS_E_PADROES.md rigorosamente:**
    - ¬ß 4: Todos arquivos ‚â§ 200 linhas
    - ¬ß 5: PT-BR, snake_case, type hints
    - ¬ß 6: Logs estruturados sem PII
    - ¬ß 9: Gates (ruff + pytest) devem passar
2. **Structured Outputs (OpenAI):**
    - Usar `beta.chat.completions.parse()` com `response_format=PydanticModel`
    - Dispon√≠vel apenas em: `gpt-4o-2024-08-06`, `gpt-4o-mini-2024-07-18`
    - Documenta√ß√£o: https://platform.openai.com/docs/guides/structured-outputs
3. **Context Injection:**
    - Preencher contextos com dados REAIS da Pyloto
    - N√£o usar placeholders em produ√ß√£o
    - Validar cada contexto ‚â§ 800 tokens
4. **Testes s√£o cr√≠ticos:**
    - N√£o pular Fase 6
    - Cobertura m√≠nima: 80% nos novos arquivos
    - E2E opcional mas altamente recomendado
5. **Deploy gradual:**
    - Staging primeiro (obrigat√≥rio)
    - Produ√ß√£o com rollout 10% ‚Üí 50% ‚Üí 100%
    - Monitorar m√©tricas continuamente

---

## CHECKLIST FINAL

Antes de considerar conclu√≠do:

- [ ] Todos arquivos ‚â§ 200 linhas
- [ ] `ruff check src/` passa sem erros
- [ ] `pytest tests/` passa 100%
- [ ] Cobertura >= 80% nos arquivos novos
- [ ] Documenta√ß√£o atualizada
- [ ] Deploy staging OK (24-48h)
- [ ] M√©tricas validadas (custo, lat√™ncia, qualifica√ß√£o)
- [ ] Rollback plan testado
- [ ] Commit final: `feat: Otto architecture v2.0.0`

---

**D√∫vidas ou bloqueios:** Abrir issue no GitHub ou consultar REGRAS_E_PADROES.md

**Boa refatora√ß√£o! üöÄ**

```
<span style="display:none">[^1]</span>

<div align="center">‚ÅÇ</div>

[^1]: Captura-de-tela-em-2026-02-04-17-06-12.jpg```
