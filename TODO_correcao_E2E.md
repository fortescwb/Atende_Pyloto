# TODO Detalhado - CorreÃ§Ãµes E2E CrÃ­ticas

TODO baseado nas **falhas concretas** encontradas bem como lacunas estruturais identificadas

**Todo cÃ³digo mostrado aqui Ã© apenas SUGESTÃƒO**
**Deve ser implementado de acordo com o que for mais lÃ³gico**
**Esse documento deve ser mantido SEMPRE atualizado**

---

## âš ï¸ BLOQUEADORES CRÃTICOS (P0) - Impedem Deploy Seguro

### 1. **Race Condition Dedupe + Perda Silenciosa de Mensagens**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Implementado fluxo `mark_processing -> mark_processed` com rollback `unmark_processing` em falha.
- Dedupe atualizado em `RedisDedupeStore` e `MemoryDedupeStore`.
- Testes adicionados/ajustados para concorrÃªncia, retry e fluxo do processor.

**Problema**:

```python
# src/app/use_cases/whatsapp/_inbound_processor.py:71-73
if await self._dedupe.is_duplicate(msg.message_id):
    return None
await self._dedupe.mark_processed(msg.message_id)
# ^ Marcado ANTES do pipeline completo
```

**CenÃ¡rio de falha**:

1. Mensagem chega, passa por `is_duplicate()` â†’ OK
2. `mark_processed()` marca como processada
3. Otto/Firestore falham
4. `webhook_runtime.py:63` engole exceÃ§Ã£o, retorna 200
5. **Mensagem perdida permanentemente**

**CorreÃ§Ã£o obrigatÃ³ria**:

```python
# src/app/use_cases/whatsapp/_inbound_processor.py

async def process(
    self,
    msg: NormalizedMessage,
    correlation_id: str,
    tenant_id: str,
) -> dict[str, Any] | None:
    # 1. Check dedupe (nÃ£o marca ainda)
    if await self._dedupe.is_duplicate(msg.message_id):
        return None

    # 2. Marca como "em processamento" com TTL curto (30s)
    await self._dedupe.mark_processing(msg.message_id, ttl=30)

    try:
        # 3. Pipeline completo
        result = await self._execute_pipeline(msg, correlation_id, tenant_id)

        # 4. Sucesso: marca como processado permanentemente
        await self._dedupe.mark_processed(msg.message_id, ttl=86400)
        return result

    except Exception as exc:
        # 5. Falha: remove marca temporÃ¡ria para permitir retry
        await self._dedupe.unmark_processing(msg.message_id)
        raise  # Propaga exceÃ§Ã£o para webhook handler decidir
```

**Implementar em `redis_dedupe_store.py`**:

```python
# src/app/infra/stores/redis_dedupe_store.py

async def mark_processing(self, message_id: str, ttl: int = 30) -> None:
    """Marca mensagem como em processamento (TTL curto)."""
    key = f"processing:{self._key_prefix}:{message_id}"
    await self._client.setex(key, ttl, "1")

async def is_duplicate(self, message_id: str) -> bool:
    """Verifica se jÃ¡ processada OU em processamento."""
    processed_key = f"{self._key_prefix}:{message_id}"
    processing_key = f"processing:{self._key_prefix}:{message_id}"

    # OperaÃ§Ã£o atÃ´mica com pipeline
    pipe = self._client.pipeline()
    pipe.exists(processed_key)
    pipe.exists(processing_key)
    results = await pipe.execute()

    return results[0] > 0 or results[1] > 0

async def unmark_processing(self, message_id: str) -> None:
    """Remove marca de processamento (em caso de falha)."""
    key = f"processing:{self._key_prefix}:{message_id}"
    await self._client.delete(key)
```

**Testes obrigatÃ³rios**:

```python
# tests/test_app/test_infra/test_redis_dedupe_store.py

async def test_dedupe_race_condition_handling():
    """Valida que mensagem nÃ£o Ã© perdida em falha apÃ³s mark_processing."""
    store = RedisDedupe(...)
    msg_id = "test_race_123"

    await store.mark_processing(msg_id, ttl=5)
    assert await store.is_duplicate(msg_id) is True

    # Simula falha: desmarcar permite retry
    await store.unmark_processing(msg_id)
    assert await store.is_duplicate(msg_id) is False

async def test_dedupe_prevents_concurrent_processing():
    """Duas tasks nÃ£o podem processar mesma mensagem simultaneamente."""
    store = RedisDedupe(...)
    msg_id = "test_concurrent_456"

    await store.mark_processing(msg_id)

    # Segunda tentativa deve detectar duplicata
    assert await store.is_duplicate(msg_id) is True
```

**Prazo**: 1 dia
**Arquivos afetados**:

- `src/app/use_cases/whatsapp/_inbound_processor.py`
- `src/app/infra/stores/redis_dedupe_store.py`
- `src/api/routes/whatsapp/webhook_runtime.py` (tratar exceÃ§Ãµes corretamente)

---

### 2. **Webhook Handler NÃ£o Propaga Erros CrÃ­ticos**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- `webhook_runtime.py` agora classifica erro de validaÃ§Ã£o vs infra e propaga exceÃ§Ãµes crÃ­ticas.
- `webhook.py` agora retorna `500` quando o dispatch falha.
- Criadas exceÃ§Ãµes de infraestrutura em `src/utils/errors/exceptions.py`.

**Problema**:

```python
# src/api/routes/whatsapp/webhook_runtime.py:63
except Exception as exc:
    logger.warning("inbound_processing_failed", ...)
    # ^ Engole exceÃ§Ã£o, retorna 200
```

**CorreÃ§Ã£o**:

```python
# src/api/routes/whatsapp/webhook_runtime.py

async def _process_inbound_task(...):
    try:
        result = await process_inbound_use_case.execute(...)
        logger.info("inbound_processed", extra={...})

    except (RedisConnectionError, FirestoreUnavailableError) as exc:
        # Erros de infraestrutura: logar como ERROR e deixar task falhar
        logger.error(
            "inbound_infrastructure_failure",
            extra={
                "correlation_id": correlation_id,
                "error_type": type(exc).__name__,
                "error_message": str(exc),
            }
        )
        # NÃƒO envolve exceÃ§Ã£o - permite que task falhe e Meta faÃ§a retry
        raise

    except ValidationError as exc:
        # Erro de dados malformados: logar mas nÃ£o retentar
        logger.warning("inbound_validation_failed", extra={...})
        # Mensagem invÃ¡lida, nÃ£o faz sentido retentar
        return

    except Exception as exc:
        # Erro desconhecido: logar e propagar
        logger.exception("inbound_unexpected_error", extra={...})
        raise
```

**Adicionar em `webhook.py`**:

```python
# src/api/routes/whatsapp/webhook.py:74

@router.post("/")
async def receive_webhook(...):
    try:
        background_tasks.add_task(...)
        return JSONResponse({"status": "received"}, status_code=200)

    except Exception as exc:
        # Se atÃ© o dispatch falhar, retornar 500 para Meta retentar
        logger.exception("webhook_dispatch_failed", ...)
        return JSONResponse(
            {"error": "internal_error", "message": "Failed to queue message"},
            status_code=500
        )
```

**Prazo**: 4 horas
**Arquivos afetados**:

- `src/api/routes/whatsapp/webhook_runtime.py`
- `src/api/routes/whatsapp/webhook.py`
- `src/utils/errors/exceptions.py` (adicionar `RedisConnectionError`, `FirestoreUnavailableError`)

---

### 3. **Readiness Check Falso Positivo**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- `/ready` agora executa checks reais de Redis, Firestore e OpenAI.
- Readiness agora responde `200` (ready) ou `503` (not_ready) conforme dependÃªncias crÃ­ticas.
- Testes adicionados em `tests/api/routes/health/test_health_route.py`.

**Problema**:

```python
# src/api/routes/health/router.py:68
# TODO: implementar checagem real de dependÃªncias
return JSONResponse({"status": "ready", "checks": {"app": "ok"}})
```

**CorreÃ§Ã£o completa**:

```python
# src/api/routes/health/router.py

from dataclasses import dataclass
from typing import Literal

@dataclass
class HealthCheck:
    status: Literal["ok", "degraded", "failed"]
    latency_ms: float | None = None
    error: str | None = None

async def check_redis(redis_client) -> HealthCheck:
    """Testa conexÃ£o Redis com timeout."""
    try:
        start = time.perf_counter()
        await asyncio.wait_for(redis_client.ping(), timeout=2.0)
        latency = (time.perf_counter() - start) * 1000
        return HealthCheck(status="ok", latency_ms=latency)
    except asyncio.TimeoutError:
        return HealthCheck(status="failed", error="timeout")
    except Exception as exc:
        return HealthCheck(status="failed", error=type(exc).__name__)

async def check_firestore(firestore_client) -> HealthCheck:
    """Testa leitura rÃ¡pida no Firestore."""
    try:
        start = time.perf_counter()
        # LÃª documento de health check (criar na inicializaÃ§Ã£o)
        doc = await asyncio.wait_for(
            firestore_client.collection("_health").document("check").get(),
            timeout=3.0
        )
        latency = (time.perf_counter() - start) * 1000
        return HealthCheck(status="ok" if doc.exists else "degraded", latency_ms=latency)
    except asyncio.TimeoutError:
        return HealthCheck(status="failed", error="timeout")
    except Exception as exc:
        return HealthCheck(status="failed", error=type(exc).__name__)

async def check_openai(openai_client) -> HealthCheck:
    """Testa API OpenAI com chamada leve."""
    try:
        start = time.perf_counter()
        # Listar modelos = chamada leve
        await asyncio.wait_for(openai_client.models.list(), timeout=5.0)
        latency = (time.perf_counter() - start) * 1000
        return HealthCheck(status="ok", latency_ms=latency)
    except asyncio.TimeoutError:
        return HealthCheck(status="degraded", error="timeout")  # Degraded, nÃ£o failed
    except Exception as exc:
        return HealthCheck(status="degraded", error=type(exc).__name__)

@router.get("/ready")
async def readiness_probe(request: Request):
    """Readiness check com validaÃ§Ã£o de dependÃªncias crÃ­ticas."""
    checks = await asyncio.gather(
        check_redis(request.app.state.redis_client),
        check_firestore(request.app.state.firestore_client),
        check_openai(request.app.state.openai_client),
        return_exceptions=True
    )

    redis_check, firestore_check, openai_check = checks

    # Redis e Firestore sÃ£o crÃ­ticos
    critical_ok = (
        redis_check.status == "ok" and
        firestore_check.status == "ok"
    )

    # OpenAI pode estar degraded (usa fallback)
    openai_ok = openai_check.status in ("ok", "degraded")

    overall_status = "ready" if (critical_ok and openai_ok) else "not_ready"
    status_code = 200 if overall_status == "ready" else 503

    return JSONResponse(
        {
            "status": overall_status,
            "checks": {
                "redis": {"status": redis_check.status, "latency_ms": redis_check.latency_ms},
                "firestore": {"status": firestore_check.status, "latency_ms": firestore_check.latency_ms},
                "openai": {"status": openai_check.status, "latency_ms": openai_check.latency_ms},
            },
            "timestamp": datetime.utcnow().isoformat(),
        },
        status_code=status_code
    )
```

**Inicializar clients no bootstrap**:

```python
# src/app/bootstrap/__init__.py

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Inicializa clients
    app.state.redis_client = await create_redis_client()
    app.state.firestore_client = create_firestore_client()
    app.state.openai_client = create_openai_client()

    # Cria documento de health check no Firestore
    await app.state.firestore_client.collection("_health").document("check").set({
        "created_at": datetime.utcnow(),
        "purpose": "readiness_probe"
    })

    yield

    # Cleanup
    await app.state.redis_client.close()
```

**Prazo**: 1 dia
**Arquivos afetados**:

- `src/api/routes/health/router.py`
- `src/app/bootstrap/__init__.py`

---

### 4. **ValidaÃ§Ã£o de ConfiguraÃ§Ã£o NÃ£o Ã© Aplicada**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Adicionado `validate_runtime_settings()` no bootstrap.
- ValidaÃ§Ã£o executada no startup/lifespan.
- Modo estrito para `staging/production`; em `development/test` registra warning sem bloquear.

**Problema**:

```python
# src/config/settings/whatsapp.py:100 define validate()
# mas src/app/bootstrap/__init__.py:37 nÃ£o chama

# Resultado: phone_number_id vazio sÃ³ falha em runtime
```

**CorreÃ§Ã£o**:

```python
# src/app/bootstrap/__init__.py

from config.settings.base.settings import Settings
from config.settings.whatsapp.api import WhatsAppSettings

def validate_all_settings():
    """Valida todas as configuraÃ§Ãµes obrigatÃ³rias no startup."""
    errors = []

    # Valida WhatsApp
    try:
        wa_settings = WhatsAppSettings()
        wa_settings.validate()
    except ValueError as exc:
        errors.append(f"WhatsApp: {exc}")

    # Valida OpenAI
    try:
        from config.settings.ai.openai import OpenAISettings
        ai_settings = OpenAISettings()
        if not ai_settings.api_key:
            errors.append("OpenAI: OPENAI_API_KEY nÃ£o configurado")
    except Exception as exc:
        errors.append(f"OpenAI: {exc}")

    # Valida Firestore
    try:
        from config.settings.infra.firestore import FirestoreSettings
        fs_settings = FirestoreSettings()
        if not fs_settings.project_id:
            errors.append("Firestore: FIRESTORE_PROJECT_ID nÃ£o configurado")
    except Exception as exc:
        errors.append(f"Firestore: {exc}")

    if errors:
        error_msg = "\n".join(f"  - {e}" for e in errors)
        raise RuntimeError(f"ConfiguraÃ§Ã£o invÃ¡lida:\n{error_msg}")

    logger.info("settings_validated", extra={"component": "bootstrap"})

@asynccontextmanager
async def lifespan(app: FastAPI):
    # Valida configuraÃ§Ãµes ANTES de qualquer inicializaÃ§Ã£o
    validate_all_settings()

    configure_logging()
    # ... resto do bootstrap
```

**Adicionar em `config/settings/whatsapp/api.py`**:

```python
def validate(self) -> None:
    """Valida configuraÃ§Ã£o obrigatÃ³ria."""
    errors = []

    if not self.phone_number_id:
        errors.append("WHATSAPP_PHONE_NUMBER_ID nÃ£o configurado")

    if not self.access_token:
        errors.append("WHATSAPP_ACCESS_TOKEN nÃ£o configurado")

    if not self.verify_token:
        errors.append("WHATSAPP_VERIFY_TOKEN nÃ£o configurado")

    if errors:
        raise ValueError("; ".join(errors))
```

**Prazo**: 4 horas
**Arquivos afetados**:

- `src/app/bootstrap/__init__.py`
- `src/config/settings/whatsapp/api.py`
- `src/config/settings/ai/openai.py` (adicionar validaÃ§Ã£o)

---

### 5. **Processamento Async Sem Durabilidade**

**Status em 2026-02-09**: âœ… **MitigaÃ§Ã£o MVP concluÃ­da**
- Implementado limite de concorrÃªncia com `Semaphore`, tracking de tasks e drain no shutdown.
- Integrado `drain_background_tasks()` no `lifespan` da aplicaÃ§Ã£o.
- Documentada limitaÃ§Ã£o e mitigaÃ§Ã£o atual no `README.md`.
- ObservaÃ§Ã£o: fila durÃ¡vel (Cloud Tasks/Streams/PubSub) permanece como evoluÃ§Ã£o futura.

**Problema**:

```python
# src/api/routes/whatsapp/webhook_runtime.py:129
asyncio.create_task(_process_inbound_task(...))
# ^ Tarefa em memÃ³ria, perdida em restart/crash
```

**SoluÃ§Ã£o pragmÃ¡tica para MVP** (sem adicionar infra de fila agora):

```python
# src/api/routes/whatsapp/webhook_runtime.py

# Adicionar limite de tasks concorrentes
_TASK_SEMAPHORE = asyncio.Semaphore(100)  # MÃ¡x 100 tasks simultÃ¢neas
_ACTIVE_TASKS: set[asyncio.Task] = set()

async def _process_with_tracking(
    process_inbound_use_case,
    payload,
    correlation_id,
    tenant_id,
):
    """Wrapper que rastreia task ativa."""
    async with _TASK_SEMAPHORE:
        try:
            await _process_inbound_task(
                process_inbound_use_case,
                payload,
                correlation_id,
                tenant_id
            )
        finally:
            # Remove da lista de tasks ativas
            pass

def dispatch_processing(...):
    """Despacha com limite e tracking."""
    task = asyncio.create_task(
        _process_with_tracking(...)
    )
    _ACTIVE_TASKS.add(task)
    task.add_done_callback(_ACTIVE_TASKS.discard)

    logger.info(
        "task_dispatched",
        extra={
            "correlation_id": correlation_id,
            "active_tasks": len(_ACTIVE_TASKS),
        }
    )

# No lifespan shutdown
async def shutdown_handler():
    """Aguarda conclusÃ£o de tasks ativas antes de desligar."""
    if _ACTIVE_TASKS:
        logger.info(
            "shutdown_awaiting_tasks",
            extra={"pending_tasks": len(_ACTIVE_TASKS)}
        )
        await asyncio.wait(_ACTIVE_TASKS, timeout=30)

        # Tasks que nÃ£o terminaram em 30s
        if _ACTIVE_TASKS:
            logger.warning(
                "shutdown_cancelled_tasks",
                extra={"cancelled_tasks": len(_ACTIVE_TASKS)}
            )
```

**Adicionar em Cloud Run**:

```yaml
# cloudbuild.yaml - adicionar termination grace period
- name: "gcr.io/cloud-builders/gcloud"
  args:
    - run
    - deploy
    - atende-pyloto
    - --timeout=30s
    - --max-instances=10
    - --termination-grace-period=60s # Aguarda 60s antes de SIGKILL
```

**Documentar limitaÃ§Ã£o**:

```markdown
# README.md - SeÃ§Ã£o "LimitaÃ§Ãµes Conhecidas"

## Processamento Async sem Fila DurÃ¡vel

**LimitaÃ§Ã£o**: Mensagens em processamento podem ser perdidas em:

- Restart manual do serviÃ§o
- Crash do processo
- Deploy com scale-down agressivo

**MitigaÃ§Ã£o atual**:

- Graceful shutdown aguarda 30s para conclusÃ£o
- Cloud Run configurado com 60s grace period
- Meta retenta mensagens nÃ£o confirmadas (webhook 5xx)

**SoluÃ§Ã£o futura (Fase 2)**:

- Implementar fila Redis Streams ou Cloud Tasks
- Garante durabilidade e retry controlado
```

**Prazo**: 6 horas
**Arquivos afetados**:

- `src/api/routes/whatsapp/webhook_runtime.py`
- `src/app/bootstrap/__init__.py` (adicionar shutdown handler)
- `cloudbuild.yaml`
- `README.md`

---

## ðŸ”´ GATES OBRIGATÃ“RIOS (P0) - Conformidade com PadrÃµes

### 6. **Corrigir 46 Erros de Lint (Ruff)**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Estado atual: **0 erros** (`ruff check .`).
- Gate de lint P0 fechado para o repositÃ³rio inteiro.

**Executar e categorizar**:

```bash
ruff check . --statistics --output-format=grouped > lint_report.txt
```

**Categorias esperadas** (baseado em projetos Python similares):

- Imports nÃ£o utilizados (~15 erros)
- VariÃ¡veis nÃ£o utilizadas (~10 erros)
- Linhas muito longas (~8 erros)
- Type hints faltando (~8 erros)
- Outros (~5 erros)

**CorreÃ§Ã£o em lote**:

```bash
# Auto-fix o que for seguro
ruff check . --fix

# Revisar manualmente o restante
ruff check . --diff
```

**Configurar Ruff corretamente**:

```toml
# pyproject.toml

[tool.ruff]
line-length = 100
target-version = "py311"

[tool.ruff.lint]
select = [
    "E",   # pycodestyle errors
    "W",   # pycodestyle warnings
    "F",   # pyflakes
    "I",   # isort
    "N",   # pep8-naming
    "UP",  # pyupgrade
    "B",   # flake8-bugbear
    "C4",  # flake8-comprehensions
    "SIM", # flake8-simplify
]

ignore = [
    "E501",  # Line too long (handled by formatter)
    "B008",  # Do not perform function calls in argument defaults (comum em FastAPI)
]

[tool.ruff.lint.per-file-ignores]
"__init__.py" = ["F401"]  # Imports nÃ£o usados em __init__ sÃ£o OK
"tests/*" = ["S101"]       # Asserts sÃ£o OK em testes
```

**Prazo**: 4 horas
**Arquivos**: MÃºltiplos (conforme relatÃ³rio)

---

### 7. **Aumentar Cobertura de 57.65% â†’ 80%**

**Status em 2026-02-09**: ðŸŸ¡ **Em andamento**
- Cobertura global atual: **66.21%** (`pytest --cov=src --cov-report=term-missing`).
- Rodadas recentes concluidas (+7.46pp global desde 58.75%).
- EvoluÃ§Ã£o dos arquivos P0 desta rodada:
  - `src/app/use_cases/whatsapp/process_inbound_canonical.py`: **76.60% â†’ 100.00%**
  - `src/app/use_cases/whatsapp/_inbound_processor.py`: **60.87% â†’ 99.13%**
  - `src/app/infra/stores/redis_dedupe_store.py`: **63.44% â†’ 100.00%**
  - `src/ai/services/otto_agent.py`: **86.57%** (mantido)
  - `src/ai/services/decision_validator.py`: **88.64%** (mantido)
- EvoluÃ§Ã£o dos arquivos P1/P2 de suporte nesta rodada:
  - `src/ai/services/contact_card_extractor.py`: **75.38% â†’ 99.23%**
  - `src/ai/utils/contact_card_extraction.py`: **41.36% â†’ 98.77%**
  - `src/api/routes/whatsapp/webhook_runtime_tasks.py`: **27.91% â†’ 100.00%**
  - `src/fsm/manager/machine.py`: **96.43% â†’ 100.00%**
  - `src/app/use_cases/whatsapp/_inbound_processor_mixin.py`: **61.93% â†’ 64.13%**
- EvoluÃ§Ã£o desta rodada:
  - `src/ai/config/prompt_assets_loader.py`: **70.33% â†’ 98.90%**
  - Cobertura global: **60.94% â†’ 66.21%**
- Testes adicionados nas rodadas recentes:
  - `tests/unit/app/use_cases/test_process_inbound_canonical_coverage.py`
  - `tests/unit/app/use_cases/test_inbound_processor_helpers.py`
  - `tests/app/infra/stores/test_redis_dedupe_store.py` (expandido)
  - `tests/test_ai/test_contact_card_extractor_coverage.py`
  - `tests/test_ai/test_contact_card_extraction_utils.py`
  - `tests/api/routes/whatsapp/test_webhook_runtime_tasks.py`
  - `tests/test_fsm/test_fsm_machine_guard_denial.py`
  - `tests/app/sessions/test_session_models.py` (expandido)
  - `tests/test_fsm/test_fsm_complete.py` (expandido)
  - `tests/test_ai/test_prompt_assets_loader.py`
  - `tests/test_e2e/test_golden_path.py`

**AnÃ¡lise de cobertura atual**:

```bash
pytest --cov=src --cov-report=html --cov-report=term-missing
# Abre htmlcov/index.html para ver arquivos sem cobertura
```

**Prioridades** (focar nos crÃ­ticos primeiro):

**A. Cobertura CrÃ­tica (P0) - ~15% de ganho**:

- `src/app/use_cases/whatsapp/process_inbound_canonical.py`
- `src/app/use_cases/whatsapp/_inbound_processor.py`
- `src/ai/services/otto_agent.py`
- `src/ai/services/decision_validator.py`
- `src/app/infra/stores/redis_dedupe_store.py`

**B. Cobertura Importante (P1) - ~10% de ganho**:

- `src/ai/services/contact_card_extractor.py`
- `src/api/routes/whatsapp/webhook_runtime_tasks.py`
- `src/fsm/manager/machine.py`

**Criar testes obrigatÃ³rios**:

```python
# tests/test_app/use_cases/whatsapp/test_process_inbound_canonical.py

@pytest.mark.asyncio
async def test_process_inbound_canonical_text_message(
    mock_normalizer,
    mock_session_manager,
    mock_dedupe,
    mock_otto_agent,
    mock_outbound_sender,
):
    """Testa fluxo completo com mensagem de texto."""
    use_case = ProcessInboundCanonicalUseCase(
        normalizer=mock_normalizer,
        session_manager=mock_session_manager,
        dedupe=mock_dedupe,
        otto_agent=mock_otto_agent,
        outbound_sender=mock_outbound_sender,
    )

    payload = {
        "entry": [{
            "changes": [{
                "value": {
                    "messages": [{
                        "id": "msg_123",
                        "from": "5544988887777",
                        "type": "text",
                        "text": {"body": "OlÃ¡, quero saber sobre SaaS"}
                    }]
                }
            }]
        }]
    }

    result = await use_case.execute(
        payload=payload,
        correlation_id="test_corr_123",
        tenant_id="pyloto"
    )

    assert result.processed == 1
    assert result.sent == 1
    assert result.skipped == 0
    assert result.final_state in ("TRIAGE", "COLLECTING_INFO")

@pytest.mark.asyncio
async def test_process_inbound_dedupe_skips_duplicate():
    """Testa que mensagem duplicada Ã© ignorada."""
    # ... implementar
    assert result.skipped == 1

@pytest.mark.asyncio
async def test_process_inbound_handles_audio_transcription():
    """Testa transcriÃ§Ã£o de Ã¡udio."""
    # ... implementar quando TranscriptionAgent existir
```

```python
# tests/test_app/infra/stores/test_redis_dedupe_store.py

@pytest.mark.asyncio
async def test_redis_dedupe_atomic_operations():
    """Valida atomicidade em operaÃ§Ãµes de dedupe."""
    # ... implementar com fixture de Redis

@pytest.mark.asyncio
async def test_redis_dedupe_ttl_expiration():
    """Valida que dedupe expira apÃ³s TTL."""
    # ... implementar
```

```python
# tests/test_ai/services/test_otto_agent.py

@pytest.mark.asyncio
async def test_otto_agent_returns_valid_decision():
    """Valida que Otto retorna decisÃ£o estruturada vÃ¡lida."""
    # ... mock OpenAI client
    # ... validar OttoDecision schema

@pytest.mark.asyncio
async def test_otto_agent_fallback_on_client_error():
    """Testa fallback quando OpenAI falha."""
    # ... implementar
```

**Prazo**: 3 dias
**Meta**: 80% de cobertura em arquivos crÃ­ticos

---

## ðŸŸ  IMPLEMENTAÃ‡Ã•ES FALTANTES (P1)

### 8. **Implementar TranscriptionAgent**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- ServiÃ§o implementado em `src/app/services/transcription_agent.py` (adaptacao arquitetural via protocolo).
- Integrado ao fluxo inbound em `src/app/use_cases/whatsapp/_inbound_processor_contact.py`.
- Testes em `tests/app/services/test_transcription_agent.py`.

**Criar serviÃ§o**:

```python
# src/ai/services/transcription_agent.py

from dataclasses import dataclass
from openai import AsyncOpenAI

@dataclass
class TranscriptionResult:
    text: str
    confidence: float
    language: str
    duration_ms: float

class TranscriptionAgentService:
    """ServiÃ§o de transcriÃ§Ã£o de Ã¡udio via Whisper API."""

    def __init__(self, openai_client: AsyncOpenAI):
        self._client = openai_client

    async def transcribe(
        self,
        audio_url: str,
        language: str = "pt",
        timeout: float = 30.0,
    ) -> TranscriptionResult:
        """Transcreve Ã¡udio do WhatsApp."""
        import time
        import httpx

        start = time.perf_counter()

        try:
            # 1. Download do Ã¡udio
            async with httpx.AsyncClient(timeout=10.0) as http:
                audio_response = await http.get(audio_url)
                audio_response.raise_for_status()
                audio_bytes = audio_response.content

            # 2. TranscriÃ§Ã£o via Whisper
            transcription = await asyncio.wait_for(
                self._client.audio.transcriptions.create(
                    model="whisper-1",
                    file=("audio.ogg", audio_bytes, "audio/ogg"),
                    language=language,
                ),
                timeout=timeout
            )

            duration_ms = (time.perf_counter() - start) * 1000

            # Whisper nÃ£o retorna confidence explÃ­cito
            # Usar heurÃ­stica: texto muito curto = baixa confidence
            confidence = 0.9 if len(transcription.text) > 10 else 0.6

            return TranscriptionResult(
                text=transcription.text,
                confidence=confidence,
                language=language,
                duration_ms=duration_ms,
            )

        except asyncio.TimeoutError:
            logger.warning("transcription_timeout", extra={"audio_url": audio_url})
            return TranscriptionResult(
                text="",
                confidence=0.0,
                language=language,
                duration_ms=(time.perf_counter() - start) * 1000,
            )
        except Exception as exc:
            logger.error(
                "transcription_failed",
                extra={
                    "audio_url": audio_url,
                    "error_type": type(exc).__name__,
                }
            )
            raise
```

**Integrar no processor**:

```python
# src/app/use_cases/whatsapp/_inbound_processor.py

async def _resolve_user_text(self, msg, session, correlation_id):
    if msg.message_type == "audio" and self._transcription_service:
        result = await self._transcription_service.transcribe(
            audio_url=msg.media_url,
            language="pt"
        )

        if result.confidence < 0.5:
            # Confidence muito baixa, pedir texto
            await self._outbound_sender.send(
                recipient=msg.sender_id,
                message=OutboundMessage(
                    text="NÃ£o consegui entender o Ã¡udio. Pode enviar texto?"
                ),
                correlation_id=correlation_id
            )
            return None, True

        return result.text, False

    # ... resto do cÃ³digo
```

**Prazo**: 1 dia
**Arquivos**:

- `src/ai/services/transcription_agent.py` (CRIAR)
- `src/app/use_cases/whatsapp/_inbound_processor.py` (atualizar)
- `tests/test_ai/services/test_transcription_agent.py` (CRIAR)

---

### 9. **Implementar Gate 3 do DecisionValidator**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Gate de revisao opcional implementado via `review_client` injetavel em `src/ai/services/decision_validator.py`.
- Cobre cenarios: aprovado, falha de review e escalonamento para humano.
- Testes em `tests/test_ai/test_decision_validator.py`.

**Atualizar validador**:

```python
# src/ai/services/decision_validator.py

class DecisionValidatorService:
    def __init__(self, openai_client: AsyncOpenAI | None = None):
        self._openai_client = openai_client
        self._llm_review_enabled = openai_client is not None

    async def validate(
        self,
        decision: OttoDecision,
        request: OttoRequest,
    ) -> ValidationResult:
        """Pipeline 3-gate de validaÃ§Ã£o."""

        # Gate 1: ValidaÃ§Ãµes determinÃ­sticas
        gate1 = self._validate_deterministic(decision, request)
        if not gate1.approved:
            return gate1

        # Gate 2: Confidence check
        if decision.confidence >= 0.85:
            return ValidationResult(approved=True, gate="confidence_high")

        if decision.confidence < 0.7:
            return ValidationResult(
                approved=False,
                gate="confidence_low",
                requires_human=True,
                reason="confidence_below_threshold"
            )

        # Gate 3: LLM review (zona cinza 0.7-0.85)
        if self._llm_review_enabled:
            gate3 = await self._llm_review(decision, request)
            return gate3

        # Fallback: aprovar com flag de incerteza
        return ValidationResult(
            approved=True,
            gate="confidence_medium",
            metadata={"requires_monitoring": True}
        )

    async def _llm_review(
        self,
        decision: OttoDecision,
        request: OttoRequest,
    ) -> ValidationResult:
        """Gate 3: RevisÃ£o leve via gpt-4o-mini."""
        prompt = f"""Revise esta decisÃ£o de atendimento:

UsuÃ¡rio: {request.user_message}
Resposta: {decision.response_text}
Estado: {request.session_state} â†’ {decision.next_state}
Confidence: {decision.confidence}

CritÃ©rios:
1. Resposta Ã© adequada ao contexto?
2. TransiÃ§Ã£o de estado faz sentido?
3. Tom Ã© profissional e Ãºtil?

Retorne JSON: {{"approved": true/false, "reason": "..."}}"""

        try:
            response = await asyncio.wait_for(
                self._openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": prompt}],
                    response_format={"type": "json_object"},
                    max_tokens=100,
                ),
                timeout=3.0
            )

            review = json.loads(response.choices[0].message.content)

            return ValidationResult(
                approved=review["approved"],
                gate="llm_review",
                reason=review.get("reason"),
                requires_human=not review["approved"],
            )

        except asyncio.TimeoutError:
            # Timeout: aprovar com flag
            return ValidationResult(
                approved=True,
                gate="llm_review_timeout",
                metadata={"requires_monitoring": True}
            )
        except Exception as exc:
            logger.warning("llm_review_failed", extra={"error": str(exc)})
            # Erro: aprovar com flag
            return ValidationResult(
                approved=True,
                gate="llm_review_error",
                metadata={"requires_monitoring": True}
            )
```

**Prazo**: 6 horas
**Arquivos**:

- `src/ai/services/decision_validator.py`
- `tests/test_ai/services/test_decision_validator.py`

---

### 10. **Corrigir Estados FSM para Strings ExplÃ­citas**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- `SessionState` migrado para `str, Enum` com valores explicitos em `src/fsm/states/session.py`.
- Compatibilidade retroativa adicionada para leitura de estados legados numericos em
  `src/app/sessions/session_entity.py`.
- Script de migracao criado em `scripts/migrate_session_states.py`.
- Testes adicionados/atualizados em `tests/app/sessions/test_session_models.py` e
  `tests/test_fsm/test_fsm_complete.py`.

**Problema atual**:

```python
# src/fsm/states/session.py usa auto()
class SessionState(Enum):
    INITIAL = auto()  # Gera int, pode variar entre versÃµes
```

**CorreÃ§Ã£o**:

```python
# src/fsm/states/session.py

class SessionState(str, Enum):
    """Estados canÃ´nicos com valores string explÃ­citos."""

    INITIAL = "INITIAL"
    TRIAGE = "TRIAGE"
    COLLECTING_INFO = "COLLECTING_INFO"
    GENERATING_RESPONSE = "GENERATING_RESPONSE"

    HANDOFF_HUMAN = "HANDOFF_HUMAN"
    SELF_SERVE_INFO = "SELF_SERVE_INFO"
    ROUTE_EXTERNAL = "ROUTE_EXTERNAL"
    SCHEDULED_FOLLOWUP = "SCHEDULED_FOLLOWUP"
    TIMEOUT = "TIMEOUT"
    ERROR = "ERROR"

    def __str__(self) -> str:
        return self.value
```

**MigraÃ§Ã£o de dados existentes** (se necessÃ¡rio):

```python
# scripts/migrate_session_states.py

async def migrate_session_states():
    """Migra estados numÃ©ricos para strings."""
    # Mapeamento auto() antigo
    OLD_TO_NEW = {
        1: "INITIAL",
        2: "TRIAGE",
        # ... resto do mapeamento
    }

    # Atualizar Firestore
    sessions = firestore_client.collection("sessions").stream()
    for session in sessions:
        data = session.to_dict()
        if isinstance(data.get("current_state"), int):
            new_state = OLD_TO_NEW.get(data["current_state"])
            if new_state:
                session.reference.update({"current_state": new_state})
```

**Prazo**: 2 horas
**Arquivos**:

- `src/fsm/states/session.py`
- `scripts/migrate_session_states.py` (CRIAR se necessÃ¡rio)

---

### 11. **Adicionar ValidaÃ§Ã£o de TransiÃ§Ãµes FSM**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Regras de transicao ativas em `src/fsm/transitions/rules.py`.
- Validacao aplicada no fluxo via `valid_transitions` no `OttoRequest` e guardas da FSM.
- Cobertura de regressao em `tests/test_fsm/test_fsm_complete.py` e
  `tests/test_fsm/test_fsm_machine_guard_denial.py`.

**Criar regras de transiÃ§Ã£o**:

```python
# src/fsm/transitions/rules.py

from src.fsm.states.session import SessionState

VALID_TRANSITIONS: dict[SessionState, set[SessionState]] = {
    SessionState.INITIAL: {
        SessionState.TRIAGE,
        SessionState.ERROR,
    },
    SessionState.TRIAGE: {
        SessionState.COLLECTING_INFO,
        SessionState.SELF_SERVE_INFO,
        SessionState.HANDOFF_HUMAN,
        SessionState.ERROR,
    },
    SessionState.COLLECTING_INFO: {
        SessionState.COLLECTING_INFO,  # Loop para coletar mais dados
        SessionState.GENERATING_RESPONSE,
        SessionState.HANDOFF_HUMAN,
        SessionState.ERROR,
    },
    SessionState.GENERATING_RESPONSE: {
        SessionState.TRIAGE,  # Nova dÃºvida
        SessionState.SELF_SERVE_INFO,
        SessionState.SCHEDULED_FOLLOWUP,
        SessionState.HANDOFF_HUMAN,
        SessionState.ROUTE_EXTERNAL,
        SessionState.ERROR,
    },
    # Estados terminais nÃ£o tÃªm transiÃ§Ãµes
    SessionState.HANDOFF_HUMAN: set(),
    SessionState.SELF_SERVE_INFO: set(),
    SessionState.ROUTE_EXTERNAL: set(),
    SessionState.SCHEDULED_FOLLOWUP: set(),
    SessionState.TIMEOUT: set(),
    SessionState.ERROR: set(),
}

def is_valid_transition(
    from_state: SessionState,
    to_state: SessionState
) -> bool:
    """Valida se transiÃ§Ã£o Ã© permitida."""
    return to_state in VALID_TRANSITIONS.get(from_state, set())
```

**Aplicar validaÃ§Ã£o no processor**:

```python
# src/app/use_cases/whatsapp/_inbound_processor_mixin.py

def _maybe_adjust_next_state(
    self,
    decision: OttoDecision,
    request: OttoRequest,
    contact_card: Any,
    correlation_id: str,
    message_id: str | None,
) -> OttoDecision:
    """Ajusta estado respeitando transiÃ§Ãµes vÃ¡lidas."""
    from fsm.transitions.rules import is_valid_transition

    current_state = SessionState(request.session_state)
    next_state = SessionState(decision.next_state)

    # Valida transiÃ§Ã£o
    if not is_valid_transition(current_state, next_state):
        logger.warning(
            "invalid_fsm_transition",
            extra={
                "component": "fsm_validator",
                "from_state": current_state.value,
                "to_state": next_state.value,
                "correlation_id": correlation_id,
                "message_id": message_id,
            }
        )

        # Fallback: manter estado atual
        return decision.model_copy(update={"next_state": current_state.value})

    return decision
```

**Prazo**: 4 horas
**Arquivos**:

- `src/fsm/transitions/rules.py` (CRIAR)
- `src/app/use_cases/whatsapp/_inbound_processor_mixin.py`
- `tests/test_fsm/test_transitions.py` (CRIAR)

---

## ðŸŸ¡ REFATORAÃ‡Ã•ES E MELHORIAS (P2)

### 12. **Quebrar `_inbound_processor_mixin.py` (300+ linhas)**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- RefatoraÃ§Ã£o aplicada com separaÃ§Ã£o por responsabilidade:
  - `src/app/use_cases/whatsapp/_inbound_processor_context.py` (181 linhas)
  - `src/app/use_cases/whatsapp/_inbound_processor_contact.py` (183 linhas)
  - `src/app/use_cases/whatsapp/_inbound_processor_dispatch.py` (152 linhas)
  - `src/app/use_cases/whatsapp/_inbound_processor_state_adjustments.py` (79 linhas)
- `src/app/use_cases/whatsapp/_inbound_processor_mixin.py` mantido como camada de compatibilidade (35 linhas) para nÃ£o quebrar imports existentes.
- `src/app/use_cases/whatsapp/_inbound_processor.py` passou a consumir os mÃ³dulos especializados.
- Testes de regressÃ£o ajustados em `tests/unit/app/use_cases/test_inbound_processor_helpers.py`.

**EstratÃ©gia**:

```
_inbound_processor_mixin.py (300+ linhas)
  â†“ dividir em â†“
â”œâ”€â”€ _inbound_processor_context.py   (contexto/prompt building)
â”œâ”€â”€ _inbound_processor_contact.py   (contact card operations)
â””â”€â”€ _inbound_processor_dispatch.py  (outbound sending)
```

**Prazo**: 4 horas
**Prioridade**: P2 (funcional, mas viola padrÃµes)

---

### 13. **Adicionar Timeouts nos `asyncio.gather`**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Timeout aplicado em `_run_agents()` com `asyncio.wait_for` no paralelo Otto + extractor.
- Fallback implementado para seguir apenas com Otto em caso de timeout.
- Cobertura adicionada em `tests/unit/app/use_cases/test_inbound_processor_helpers.py`.

```python
# src/app/use_cases/whatsapp/_inbound_processor.py

async def _run_agents(...):
    try:
        decision, extraction = await asyncio.wait_for(
            asyncio.gather(
                self._otto_agent.decide(otto_request),
                self._contact_card_extractor.extract(...) if self._contact_card_extractor else _dummy_extraction(),
            ),
            timeout=5.0  # 5s mÃ¡ximo para ambos
        )
    except asyncio.TimeoutError:
        logger.warning("agents_timeout", ...)
        # Fallback: usar apenas Otto (extractor falhou)
        decision = await self._otto_agent.decide(otto_request)
        extraction = None

    return otto_request, decision, extraction
```

**Prazo**: 2 horas

---

### 14. **Cache de Contextos YAML no Bootstrap**

**Status em 2026-02-09**: âœ… **ConcluÃ­do (implementado na camada correta)**
- Cache de contextos/prompt jÃ¡ estava implementado com `@lru_cache` em
  `src/ai/config/prompt_assets_loader.py` (`load_context_text`, `load_context_for_prompt`, `load_prompt_yaml`).
- Mantido em `ai/config` para respeitar boundaries (evitando acoplamento `ai` â†’ `app/bootstrap`).
- Cobertura de regressÃ£o adicionada em `tests/test_ai/test_prompt_assets_loader.py`.
- Resultado: `prompt_assets_loader.py` subiu para **98.90%** de cobertura.

```python
# src/app/bootstrap/context_cache.py

from functools import lru_cache

@lru_cache(maxsize=50)
def load_context_cached(path: str) -> str:
    """Carrega contexto YAML com cache."""
    from ai.config.prompt_assets_loader import load_context_for_prompt
    return load_context_for_prompt(path)
```

**Prazo**: 2 horas

---

### 15. **Teste E2E Golden Path**

**Status em 2026-02-09**: âœ… **ConcluÃ­do**
- Teste E2E adicionado em `tests/test_e2e/test_golden_path.py` cobrindo fluxo:
  saudaÃ§Ã£o â†’ interesse SaaS â†’ atualizaÃ§Ã£o de sessÃ£o/estado â†’ atualizaÃ§Ã£o de ContactCard.
- Implementado com pipeline canÃ´nico real (`ProcessInboundCanonicalUseCase`) e doubles determinÃ­sticos
  para Otto/Extractor/Outbound, sem rede real.
- Marker `e2e` registrado em `pyproject.toml` para manter `--strict-markers`.
- ValidaÃ§Ã£o local: `pytest -q tests/test_e2e/test_golden_path.py` (verde).

```python
# tests/test_e2e/test_golden_path.py

@pytest.mark.e2e
@pytest.mark.asyncio
async def test_full_conversation_saas_interest(
    test_client,
    redis_client,
    firestore_client,
):
    """Testa fluxo completo: saudaÃ§Ã£o â†’ interesse SaaS â†’ coleta email â†’ resposta."""

    # 1. Primeira mensagem: saudaÃ§Ã£o
    response = await test_client.post(
        "/webhook/whatsapp/",
        json=create_whatsapp_payload(
            message_id="msg_001",
            from_number="5544988887777",
            text="OlÃ¡"
        ),
        headers={"X-Hub-Signature-256": "..."}
    )
    assert response.status_code == 200

    # Aguarda processamento
    await asyncio.sleep(2)

    # Valida sessÃ£o criada
    session = await firestore_client.collection("sessions").document("5544988887777").get()
    assert session.exists
    assert session.to_dict()["current_state"] == "TRIAGE"

    # 2. Segunda mensagem: interesse
    response = await test_client.post(
        "/webhook/whatsapp/",
        json=create_whatsapp_payload(
            message_id="msg_002",
            from_number="5544988887777",
            text="Quero saber sobre o SaaS da Pyloto"
        ),
    )

    # Valida transiÃ§Ã£o de estado
    session = await firestore_client.collection("sessions").document("5544988887777").get()
    assert session.to_dict()["current_state"] in ("COLLECTING_INFO", "GENERATING_RESPONSE")

    # Valida ContactCard
    contact = await firestore_client.collection("contact_cards").document("5544988887777").get()
    assert contact.to_dict()["primary_interest"] == "saas"

    # ... continuar fluxo
```

**Prazo**: 1 dia

---

## ðŸ“Š RESUMO DE PRIORIDADES

### **CrÃ­tico (P0) - Deploy Blocker**

| \#  | Item                   | Prazo  | Status      |
| :-- | :--------------------- | :----- | :---------- |
| 1   | Race condition dedupe  | 1 dia  | âœ…          |
| 2   | Webhook error handling | 4h     | âœ…          |
| 3   | Readiness check        | 1 dia  | âœ…          |
| 4   | ValidaÃ§Ã£o de config    | 4h     | âœ…          |
| 5   | Async sem durabilidade | 6h     | âœ… (MVP)    |
| 6   | Corrigir 46 erros lint | 4h     | âœ… (0 pendentes) |
| 7   | Cobertura 80%          | 3 dias | ðŸŸ¡ (66.21%) |

**Total P0**: ~6 dias Ãºteis

### **Importante (P1) - MVP Completo**

| \#  | Item                 | Prazo | Status |
| :-- | :------------------- | :---- | :----- |
| 8   | TranscriptionAgent   | 1 dia | âœ…     |
| 9   | Gate 3 validator     | 6h    | âœ…     |
| 10  | Estados FSM string   | 2h    | âœ…     |
| 11  | ValidaÃ§Ã£o transiÃ§Ãµes | 4h    | âœ…     |

**Total P1**: ~2 dias Ãºteis

### **DesejÃ¡vel (P2) - Polish**

| \#  | Item            | Prazo | Status |
| :-- | :-------------- | :---- | :----- |
| 12  | Refatorar mixin | 4h    | âœ…     |
| 13  | Timeouts gather | 2h    | âœ…     |
| 14  | Cache contextos | 2h    | âœ…     |
| 15  | Teste E2E       | 1 dia | âœ…     |

---

## ðŸŽ¯ PLANO DE EXECUÃ‡ÃƒO RECOMENDADO

### **Semana 1 (5 dias)**

- **Dia 1-2**: P0.1, P0.2, P0.3, P0.4 (infraestrutura crÃ­tica)
- **Dia 3**: P0.5 (async durability) + P0.6 (lint)
- **Dia 4-5**: P0.7 (testes para 80%)

### **Semana 2 (3 dias)**

- **Dia 6**: P1.8 (TranscriptionAgent) + P1.10 (FSM strings)
- **Dia 7**: P1.9 (Gate 3) + P1.11 (validaÃ§Ã£o transiÃ§Ãµes)
- **Dia 8**: Deploy staging + validaÃ§Ã£o 48h

### **Semana 3 (opcional)**

- P2: RefatoraÃ§Ãµes e polish

**Pronto para produÃ§Ã£o**: Fim da Semana 2
